# .env.example
# CRT Configuration Template
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# OpenAI API Key (required for default setup)
OPENAI_API_KEY=your-openai-api-key-here

# Alternative: Local LLM (Ollama)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=mistral

# =============================================================================
# Database Paths
# =============================================================================

# Memory database (stores conversation history and facts)
CRT_DB_PATH=./personal_agent/crt_memory.db

# Contradiction ledger database (tracks conflicts)
CRT_LEDGER_PATH=./personal_agent/crt_ledger.db

# =============================================================================
# Server Configuration
# =============================================================================

# API server host and port
API_HOST=127.0.0.1
API_PORT=8123

# Frontend dev server port
FRONTEND_PORT=5173

# =============================================================================
# Logging
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (optional, logs to console if not set)
# LOG_FILE=./logs/crt.log

# =============================================================================
# Memory & Retrieval Configuration
# =============================================================================

# Number of memories to retrieve per query
RETRIEVAL_TOP_K=5

# Minimum trust score for memory retrieval (0.0 to 1.0)
MIN_TRUST_THRESHOLD=0.3

# Recency decay factor (higher = older memories decay faster)
RECENCY_DECAY=0.95

# Belief weight alpha (0.0 = pure trust, 1.0 = pure confidence)
BELIEF_ALPHA=0.7

# =============================================================================
# Gate Configuration
# =============================================================================

# Intent alignment threshold (0.0 to 1.0)
INTENT_ALIGNMENT_THRESHOLD=0.6

# Memory alignment threshold (0.0 to 1.0)
MEMORY_ALIGNMENT_THRESHOLD=0.4

# Contradiction confidence threshold (0.0 to 1.0)
CONTRADICTION_CONFIDENCE_THRESHOLD=0.7

# =============================================================================
# Development/Debug Settings
# =============================================================================

# Enable debug mode (DO NOT use in production)
DEBUG=false

# Enable verbose logging
VERBOSE=false

# Enable stress test mode
STRESS_TEST_MODE=false

# =============================================================================
# Background Jobs (Optional)
# =============================================================================

# Enable background learning worker
ENABLE_BACKGROUND_LEARNING=false

# Job polling interval (seconds)
JOB_POLL_INTERVAL=60

# Maximum concurrent background jobs
MAX_BACKGROUND_JOBS=3

# =============================================================================
# Security (Production Only)
# =============================================================================

# API authentication token (optional, for production deployment)
# API_AUTH_TOKEN=your-secret-token-here

# CORS allowed origins (comma-separated)
# CORS_ORIGINS=http://localhost:5173,https://yourdomain.com

# =============================================================================
# Notes
# =============================================================================

# 1. This file should NOT be committed to version control
# 2. Add .env to .gitignore (already done)
# 3. For production, use environment variables instead of .env file
# 4. For local development, copying this to .env is fine
