# CRT + GroundCheck: Honest AI Memory

> **Contradiction-preserving memory for AI agents. No silent overwrites.**

## Quick Start (30 seconds)

```python
from personal_agent.crt_rag import CRTEnhancedRAG

# Initialize
rag = CRTEnhancedRAG()

# Store facts - contradictions are PRESERVED, not overwritten
rag.process_user_input("I work at Microsoft", thread_id="demo")
rag.process_user_input("I work at Amazon", thread_id="demo")  # Contradiction!

# Query - system shows BOTH values, asks for clarification
result = rag.query("Where do I work?", thread_id="demo")
# â†’ "You mentioned working at Microsoft AND Amazon. Which is current?"

# The system REFUSES to pick a winner silently
# This is the core invariant: no confident lies about contradicted facts
```

```bash
# Install
pip install -e .

# Run API
uvicorn crt_api:app --reload --port 8123

# Stress test (30 turns, local only, no API keys needed)
python tools/crt_stress_test.py --turns 30 --sleep 0.03
```

---

## The Problem

Long-term AI assistants accumulate contradictory facts as user information updates over time (job changes, location moves, preference shifts). Most systems silently overwrite old facts or randomly pick between conflicts, presenting uncertain information as confident truth.

## The Approach

**CRT (Contradiction Resolution & Trust)** â€” Memory governance layer
- Preserves contradictions in queryable ledger instead of overwriting
- Two-lane architecture: stable facts vs. unconfirmed candidates
- Trust scores evolve as facts age or get confirmed
- Policy engine defines how contradictions should be handled

**GroundCheck** â€” Output verification layer  
- Detects when generated text uses contradicted facts
- Verifies output acknowledges contradictions appropriately
- Enforces disclosure or generates corrections
- Deterministic (regex-based), zero LLM calls, <10ms

**Together:** End-to-end "honesty pipeline" from storage â†’ retrieval â†’ output

## Core Invariant

If retrieved memory contains mutually exclusive values for the same slot (both above trust threshold), the system must either:
1. Disclose both values in the output ("Amazon (changed from Microsoft)")
2. Ask the user for clarification
3. NOT present one value as definitive truth

## What We Can Prove

**Contradiction detection:**
- 60% accuracy on contradiction category (GroundingBench, 6/10 examples)
- Baselines (SelfCheckGPT-style, CoVe-style): 30% (3/10 examples)
- 2x improvement on this specific capability

**System properties:**
- 86 tests passing (groundcheck library)
- 97 tests passing (full CRT system)
- Contradiction ledger: 1000+ entries tracked without loss (stress test)
- Verification speed: <10ms per check
- Zero API costs (deterministic logic)

**Overall grounding:**
- 70% accuracy on GroundingBench (35/50 examples)
- Competitive but not state-of-art (SelfCheckGPT ~82%)
- Trade-off: Speed + contradiction handling vs raw accuracy

## Limitations (Being Honest)

**Fact extraction:**
- Two-tier system: Regex for hard slots (20+ predefined) + optional LLM for open tuples
- Hard slots (Tier A): Deterministic, high precision for critical facts (name, employer, location)
- Open tuples (Tier B): LLM-based, can extract flexible facts (hobbies, preferences) but requires LLM
- Cannot extract domain-specific facts without LLM tier
- English-only patterns for regex tier

**Accuracy:**
- 70% overall grounding (vs 82% for SelfCheckGPT on basic grounding)
- 60% contradiction detection (still misses 4/10 cases)
- Known failures: substring matching, missing patterns, complex paraphrases

**Scope:**
- Text-only (no multi-modal contradiction detection)
- Trust thresholds (0.75, 0.3) chosen empirically, not learned
- English-only patterns

**Maturity:**
- Research prototype (v0.9-beta)
- Not production-hardened
- SQLite storage (not designed for >100K users)

## Where This Could Help

**Personal AI assistants:**
- Prevent gaslighting when facts change
- Build trust through transparency
- Show history, not just current state

**Healthcare:**
- Track diagnosis evolution (initial positive â†’ retest negative)
- Audit trail for contradictory test results
- Disclosure compliance (HIPAA)

**Legal:**
- Flag contradictory witness statements
- Track testimony evolution
- Discovery compliance

**Enterprise knowledge:**
- Detect conflicting documentation
- Version tracking for policies
- Reduce errors from stale information

**Customer service:**
- Acknowledge account history changes
- Transparent updates ("shipping address changed from...")
- Build customer trust

## Architecture

```
User Input â†’ CRT Memory Layer â†’ Retrieval â†’ LLM Generation â†’ 
GroundCheck Verification â†’ Corrected Output (if needed) â†’ User
                â†“                                              â†“
         Ledger Update â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**CRT components:**
- Two-lane memory (stable + candidate)
- Contradiction ledger (tracks conflicts)
- Trust evolution (facts age, confirmations boost)
- Policy engine (MANDATORY_DISCLOSURE, PREFER_NEWER, ASK_USER, MERGE)
- **Two-tier fact extraction:**
  - **Tier A (Hard Slots):** Regex-based for critical facts (name, employer, location, etc.)
  - **Tier B (Open Tuples):** Optional LLM-based for flexible facts (hobbies, preferences, goals)
  - Graceful degradation: Falls back to regex-only if LLM unavailable

**GroundCheck components:**
- Fact extractor (two-tier: regex + optional LLM)
- Contradiction detector (groups facts by slot, finds conflicts across both tiers)
- Disclosure verifier (checks for acknowledgment patterns)
- Correction generator (suggests proper disclosure)

## Technical Differentiators

**vs. SelfCheckGPT:**
- They: Check output consistency via LLM sampling
- We: Check retrieved memory for contradictions
- Trade-off: We're faster + cheaper, they're more accurate on basic grounding

**vs. Chain-of-Verification:**
- They: LLM generates verification questions
- We: Deterministic pattern matching + contradiction ledger
- Trade-off: We're deterministic + explainable, they handle arbitrary claims

**vs. ChatGPT Memory / Claude Projects:**
- They: Overwrite or randomly pick between conflicts
- We: Preserve contradictions + enforce disclosure
- Unique: Explicit contradiction tracking + policy enforcement

---

## ğŸš€ Quick Start (5 Minutes)

### Prerequisites
- **Python 3.10+**
- **Ollama** (for natural language responses)
  ```bash
  # Install: https://ollama.com/download
  ollama pull llama3.2:latest
  ollama serve
  ```
- **Node.js 18+** (for web UI, optional)

### Installation

```bash
# 1. Clone and setup Python
cd d:\AI_round2
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Mac/Linux

pip install -r requirements.txt

# 2. Start API server
python -m uvicorn crt_api:app --reload --host 127.0.0.1 --port 8123
# Wait for: "Uvicorn running on http://127.0.0.1:8123"
```

### Quick Demo (2 Minutes)

**PowerShell (Windows):**
```powershell
# Create contradiction
$thread = "quick_demo"
$api = "http://127.0.0.1:8123/api/chat/send"

$b1 = @{thread_id=$thread; message="I work at Microsoft."} | ConvertTo-Json
Invoke-RestMethod -Uri $api -Method POST -Body $b1 -ContentType "application/json"

$b2 = @{thread_id=$thread; message="Actually, I work at Amazon, not Microsoft."} | ConvertTo-Json
Invoke-RestMethod -Uri $api -Method POST -Body $b2 -ContentType "application/json"

# Recall contradicted fact
$b3 = @{thread_id=$thread; message="Where do I work?"} | ConvertTo-Json
$r = Invoke-RestMethod -Uri $api -Method POST -Body $b3 -ContentType "application/json"

Write-Host "Answer: $($r.answer)"
# Expected: "Amazon (most recent update)"
Write-Host "Contradicted claims: $($r.metadata.reintroduced_claims_count)"
# Expected: 2
```

**bash/curl (Linux/macOS/WSL):**
```bash
# Create contradiction
THREAD="quick_demo"
API="http://127.0.0.1:8123/api/chat/send"

curl -X POST $API -H "Content-Type: application/json" \
  -d "{\"thread_id\":\"$THREAD\",\"message\":\"I work at Microsoft.\"}"

curl -X POST $API -H "Content-Type: application/json" \
  -d "{\"thread_id\":\"$THREAD\",\"message\":\"Actually, I work at Amazon, not Microsoft.\"}"

# Recall contradicted fact (pipe to jq for pretty JSON)
curl -X POST $API -H "Content-Type: application/json" \
  -d "{\"thread_id\":\"$THREAD\",\"message\":\"Where do I work?\"}" | jq '.answer, .metadata.reintroduced_claims_count'

# Expected: "Amazon (most recent update)" and 2
```

**âœ… Success:** Answer includes caveat, count = 2, both memories flagged

## Status

- GroundCheck library: Published (pip installable)
- GroundingBench: 50 seed examples (expandable to 500)
- Paper: Submitted to arXiv (Jan 2026)
- CRT system: Research prototype, documented architecture
- License: MIT (GroundCheck), open source

## Next Steps

1. Publish paper + dataset to arXiv
2. Expand GroundingBench to 500 examples
3. Build "Truth-Change Bench" focused on temporal contradictions
4. Run real baselines (actual SelfCheckGPT code, not mocks)
5. Case study: integrate with open source chatbot
6. Measure real-world performance (false positive/negative rates)

## Does This Actually Help?

**The honest answer: Maybe.**

**If you care about:**
- AI systems being transparent about uncertainty
- Long-term memory that doesn't gaslight users
- Audit trails for evolving facts
- Compliance in regulated domains

**Then yes, this approach could help.**

**If you just want:**
- Highest accuracy on basic grounding â†’ Use SelfCheckGPT
- General hallucination detection â†’ Use FActScore
- Fast RAG without verification â†’ This adds overhead

**This system solves a specific problem: handling contradictions in long-term memory.**

**That problem matters for some use cases (personal AI, healthcare, legal).**  
**It doesn't matter for others (one-shot QA, stateless chatbots).**

**We're publishing it so others can evaluate, extend, or integrate if it helps their work.**

---

## ğŸ“– Documentation

**â†’ [Full Documentation Index](DOCUMENTATION_INDEX.md)** - Complete navigation guide

### Start Here
- **[ELEVATOR_PITCH.md](ELEVATOR_PITCH.md)** - **30-second summary** of problem, solution, and technical contribution
- **[PURPOSE.md](PURPOSE.md)** - **Why does this project exist?** (Honest impact assessment)
- **[BEFORE_AND_AFTER.md](BEFORE_AND_AFTER.md)** - **Side-by-side comparison** showing the difference CRT makes
- **[docs/HONEST_ASSESSMENT.md](docs/HONEST_ASSESSMENT.md)** - **Brutal honesty** about what works, what doesn't, and what we don't know
- **[BETA_STARTER_KIT.md](BETA_STARTER_KIT.md)** - Beta tester guide with 5-minute demo
- **[QUICKSTART.md](QUICKSTART.md)** - Detailed installation + setup
- **[DEMO_5_TURN.md](DEMO_5_TURN.md)** - Quick contradiction demonstration

### Technical Specs
- **[CRT_REINTRODUCTION_INVARIANT.md](CRT_REINTRODUCTION_INVARIANT.md)** - Complete invariant specification
- **[BETA_RELEASE_NOTES.md](BETA_RELEASE_NOTES.md)** - v0.9-beta changelog
- **[CRT_WHITEPAPER.md](CRT_WHITEPAPER.md)** - Architecture deep dive

### Validation
- **[BETA_READINESS_SUMMARY.md](BETA_READINESS_SUMMARY.md)** - Smoke test results
- **[BETA_VERIFICATION_CHECKLIST.md](BETA_VERIFICATION_CHECKLIST.md)** - 10-minute validation script
- **Proof Artifact:** `artifacts/crt_stress_run.20260121_162816.jsonl` (0 violations)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚  React + TypeScript
â”‚                 â”‚  Visual indicators for contradicted claims
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Server (crt_api.py)      â”‚
â”‚                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Reintroduction Enforcer  â”‚     â”‚  â† v0.9-beta
â”‚   â”‚ (API serialization)      â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ CRT Core (crt_rag.py)â”‚
    â”‚ - Truth coherence    â”‚
    â”‚ - Inline caveats     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚              â”‚             â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚Memory  â”‚   â”‚Contradiction â”‚  â”‚Researchâ”‚  â”‚  Jobs  â”‚
â”‚System  â”‚   â”‚   Ledger     â”‚  â”‚ Engine â”‚  â”‚ Worker â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (SQLite)      (SQLite)         (Hybrid)   (Background)
```

### Data Flow: Contradiction Handling

```
1. User: "I work at Microsoft"
   â†’ Memory stored, trust=0.7

2. User: "Actually, I work at Amazon"
   â†’ Contradiction detected
   â†’ Ledger entry: Microsoft vs Amazon (status=open)
   â†’ Both memories preserved

3. User: "Where do I work?"
   â†’ Query retrieves both memories
   â†’ API calls ledger.has_open_contradiction(memory_id)
   â†’ Sets reintroduced_claim=true on both
   â†’ Truth coherence adds caveat: "(most recent update)"
   â†’ Response: "Amazon (most recent update)"
   â†’ metadata.reintroduced_claims_count = 2
```

---

## ğŸ“‚ Project Structure

```
/crt_api.py                    # FastAPI server (version 0.9-beta)
/personal_agent/
  â”œâ”€â”€ crt_rag.py               # Core retrieval + truth coherence
  â”œâ”€â”€ crt_memory.py            # Memory storage & retrieval
  â”œâ”€â”€ crt_ledger.py            # Contradiction tracking
  â””â”€â”€ research_engine.py       # External knowledge integration
/frontend/                     # React web interface
  â””â”€â”€ src/components/chat/
      â””â”€â”€ MessageBubble.tsx    # Visual contradiction indicators
/tools/
  â””â”€â”€ crt_stress_test.py       # Automated validation (15-30 turns)
/tests/                        # Pytest test suite
/artifacts/                    # Stress test reports & proof artifacts
/docs/                         # Additional documentation

Key Files:
- CRT_REINTRODUCTION_INVARIANT.md   # Invariant specification
- BETA_STARTER_KIT.md               # Tester onboarding guide
- DEMO_5_TURN.md                    # Quick demonstration script
```

---

## ğŸ§ª Testing & Validation

### Smoke Test (2 minutes)
```bash
# See BETA_VERIFICATION_CHECKLIST.md for copy-paste script
# Tests: Memory â†’ Contradiction â†’ Recall â†’ Flags
```

### Stress Test (15 turns)
```bash
python tools/crt_stress_test.py \
  --use-api \
  --api-base-url http://127.0.0.1:8123 \
  --thread-id test_run \
  --reset-thread \
  --turns 15 \
  --sleep 0.05

# Expected output:
# REINTRODUCTION INVARIANT (v0.9-beta):
#   Flagged (audited): N
#   Unflagged (violations): 0
#   Asserted without caveat (violations): 0
#   âœ… INVARIANT MAINTAINED
```

### Unit Tests
```bash
pytest tests/ -v
```

---

## ğŸ“Š Current Status

**Version:** v0.9-beta  
**Released:** January 21, 2026  
**Status:** Research prototype

### âœ… What's Working
- **Reintroduction invariant enforcement** (0 violations in stress tests)
- API-layer flag enforcement (`reintroduced_claim` field on all memories)
- Truth coherence disclosure (inline caveats in answers)
- X-Ray transparency (memory provenance + contradiction flags)
- Visual UI indicators (badges for contradicted claims)
- Two-lane memory (BELIEF/SPEECH separation)
- Contradiction detection & tracking

### âš ï¸ Known Limitations
1. **Caveat detection:** Keyword-based ("most recent", "latest", etc.)
   - Can be gamed with careful phrasing
   - Future: upgrade to semantic detection

2. **Ollama dependency:** Requires local LLM for natural answers
   - Graceful degradation: Returns error messages without Ollama
   - Memory/flags still work, just no natural language

3. **Regex limitations:** Only handles predefined fact types
   - Cannot extract domain-specific facts
   - Misses complex linguistic variations

---

## Does This Matter? (Honest Answer)

**We don't know yet.**

**What we know:**
- Contradiction detection works (60% vs 30% baselines)
- System is fast and deterministic
- Architecture is sound

**What we don't know:**
- Will users prefer disclosure to confident errors?
- Are contradictions common enough to matter?
- Will regulations require this?
- Can this scale to production?

**We're publishing because:**
- The problem is real (AI memory has contradictions)
- The approach is novel (first explicit contradiction tracking)
- Others can evaluate if it helps their use case
- Research should be reproducible and extensible

**We're NOT claiming:**
- This will definitely be adopted
- It's better for all use cases
- It's production-ready
- Everyone needs this

**If you're working on:**
- Long-term AI memory â†’ This might help
- Regulated AI (healthcare, legal) â†’ This might help
- Personal assistants â†’ This might help
- One-shot QA â†’ This probably doesn't help
- Stateless chatbots â†’ This doesn't help

**Try it. Evaluate it. Extend it if useful. Ignore it if not.**

That's why we published.

---

## ğŸ“„ License

[Add your license here]

---

**Built with:** Python 3.10+, FastAPI, React, SQLite, Ollama, sentence-transformers  
**Philosophy:** Uncertainty-honest AI that preserves contradictions instead of hiding them
