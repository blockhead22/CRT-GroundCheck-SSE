# Cross-Thread Memory Sharing: Comprehensive Design Assessment

**Document Version:** 1.0  
**Date:** January 23, 2026  
**Status:** Design Assessment (Implementation Pending)  
**Author:** CRT System Architecture Team

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Current Architecture Analysis](#2-current-architecture-analysis)
3. [Option 1: Global User Database](#3-option-1-global-user-database)
4. [Option 2: Unified Database with Scoping](#4-option-2-unified-database-with-scoping)
5. [Option 3: Federated Query Across Thread Databases](#5-option-3-federated-query-across-thread-databases)
6. [Option 4: Lazy Migration on Thread Start](#6-option-4-lazy-migration-on-thread-start)
7. [Option 5: Hybrid Profile + Thread Context](#7-option-5-hybrid-profile--thread-context)
8. [Comparison Matrix](#8-comparison-matrix)
9. [Contradiction Handling Strategy](#9-contradiction-handling-strategy)
10. [Privacy Assessment](#10-privacy-assessment)
11. [Performance Benchmarks](#11-performance-benchmarks)
12. [Migration Plan](#12-migration-plan)
13. [Recommended Approach](#13-recommended-approach)

---

## 1. Executive Summary

### The Problem

The CRT (Contradiction-aware RAG with Trust) system currently isolates memories by `thread_id`. Each conversation thread maintains its own isolated database:
- Memory database (`crt_memory_{thread_id}.db`)
- Contradiction ledger (`crt_ledger_{thread_id}.db`)
- Active learning logs (`crt_active_learning_{thread_id}.db`)

**User Pain Point:**
```
Thread 1 (Yesterday): "My name is Nick, I work at Google"
Thread 2 (Today):     "What's my name?" â†’ "I don't know" âŒ
```

### Assessment Scope

This document evaluates **5 architectural approaches** for cross-thread memory sharing:
1. **Global User Database** - Separate global + thread-specific databases
2. **Unified Database with Scoping** - Single database with scope flags
3. **Federated Query** - Query across multiple thread databases
4. **Lazy Migration** - Copy memories on thread start/end
5. **Hybrid Profile + Context** - Separate stable profile from ephemeral context

For each option, we assess:
- âœ… **UX Quality** - How natural is the user experience?
- âš¡ **Performance** - Query speed at scale (100+ threads)
- ðŸ”’ **Privacy Control** - Can users isolate sensitive threads?
- ðŸ› ï¸ **Implementation Complexity** - Dev effort & migration risk
- ðŸ“ˆ **Scalability** - Performance with 10K+ memories

### Key Findings

| Option | Best For | Major Limitation |
|--------|----------|------------------|
| **Option 1: Global DB** | Clean separation, multi-device sync | Two-database complexity |
| **Option 2: Unified DB** | Single source of truth | Large database, harder thread isolation |
| **Option 3: Federated** | No schema changes, easy rollback | Poor performance (N database connections) |
| **Option 4: Lazy Copy** | Thread independence preserved | Stale data, complex sync logic |
| **Option 5: Hybrid** â­ | **Best balance** of all factors | Need to classify facts as profile/context |

### Recommendation Preview

**Option 5 (Hybrid Profile + Context)** is recommended because:
- âœ… Clear separation: stable facts vs. ephemeral context
- âœ… Fast queries (profile is small, ~100 facts)
- âœ… Natural UX (users understand "profile" concept)
- âœ… Easy privacy control (profile separate from threads)
- âœ… Aligns with industry patterns (agent-zero, LangChain)

**Implementation Timeline:** 1-2 weeks (see Section 13)


---

## 2. Current Architecture Analysis

### 2.1 Database Structure

**Current Per-Thread Isolation:**
```
personal_agent/
â”œâ”€â”€ crt_memory_{thread_id}.db
â”‚   â”œâ”€â”€ memories (memory_id, vector_json, text, timestamp, confidence, trust, source, sse_mode, thread_id, ...)
â”‚   â”œâ”€â”€ trust_log (tracks trust evolution)
â”‚   â””â”€â”€ belief_speech (tracks belief vs speech separation)
â”œâ”€â”€ crt_ledger_{thread_id}.db
â”‚   â””â”€â”€ contradictions (ledger_id, old_memory_id, new_memory_id, status, affects_slots, ...)
â””â”€â”€ crt_active_learning_{thread_id}.db
    â””â”€â”€ interaction_logs (logs active learning interactions)
```

**Schema: memories table**
```sql
CREATE TABLE memories (
    memory_id TEXT PRIMARY KEY,
    vector_json TEXT NOT NULL,        -- Semantic embedding
    text TEXT NOT NULL,                -- Memory text
    timestamp REAL NOT NULL,           -- Unix timestamp
    confidence REAL NOT NULL,          -- [0,1] certainty at creation
    trust REAL NOT NULL,               -- [0,1] validated over time
    source TEXT NOT NULL,              -- user/system/fallback/reflection
    sse_mode TEXT NOT NULL,            -- L/C/H (compression level)
    context_json TEXT,                 -- Additional context
    tags_json TEXT,                    -- Tags
    thread_id TEXT,                    -- Current: same for all in DB
    deprecated INTEGER DEFAULT 0,      -- Superseded memory flag
    deprecation_reason TEXT
);
```

### 2.2 Current Memory Retrieval

**File:** `personal_agent/crt_memory.py`

```python
def retrieve_memories(
    self,
    query: str,
    k: int = 5,
    min_trust: float = 0.0,
    exclude_deprecated: bool = True
) -> List[Tuple[MemoryItem, float]]:
    """
    Retrieve memories using trust-weighted scoring.
    
    Scoring: R_i = s_i Â· Ï_i Â· w_i
    where:
    - s_i = similarity to query (cosine similarity of embeddings)
    - Ï_i = recency weight (exponential decay)
    - w_i = belief weight (Î±Â·trust + (1-Î±)Â·confidence)
    """
    query_vector = encode_vector(query)
    
    # Load all memories from SINGLE thread database
    memories = self._load_all_memories()  # â† LIMITATION: One thread only
    
    # Filter deprecated
    if exclude_deprecated:
        memories = [m for m in memories if not m.deprecated]
    
    # Compute trust-weighted scores
    scores = self.crt_math.compute_retrieval_scores(
        query_vector=query_vector,
        memories=memory_dicts,
        t_now=time.time()
    )
    
    # Return top k
    return [(memories[idx], score) for idx, score in scores[:k]]
```

**Current Limitation:** Only queries single thread's database. No cross-thread visibility.

### 2.3 CRT Core Principles (Must Preserve)

Any cross-thread solution **MUST maintain** these invariants:

1. **No Silent Overwrites** - Contradictions create ledger entries, not deletions
2. **Trust Evolution** - Trust scores evolve based on alignment/drift over time
3. **Belief vs Speech Separation** - Fallback can speak, but creates low-trust memories
4. **SSE Modes** - Semantic compression (L/C/H) based on significance
5. **Provenance Tracking** - Clear source attribution (user/system/fallback/reflection)

### 2.4 Global User Profile (Existing Component)

**File:** `personal_agent/user_profile.py`

The system already has a `GlobalUserProfile` class used for:
- User preferences (e.g., "call me Nick")
- Metadata (job, location)
- **Currently minimal usage** in memory retrieval

This is a **key insight**: We already have infrastructure for global state, just underutilized.

### 2.5 Key Metrics (Current State)

**Observed from codebase:**
- ~10-50 memories per thread (typical conversation)
- ~100-500 threads per power user (over months)
- ~0.85 average trust for user-sourced memories
- ~0.4-0.6 trust for system/fallback memories
- 5-10ms query time for single thread (small DB)

**Pain Points:**
- New thread = cold start (no prior knowledge)
- User must re-state basics ("My name is...", "I work at...")
- Inconsistent UX vs. other AI assistants (ChatGPT, Claude remember across sessions)


---

## 3. Option 1: Global User Database

### 3.1 Architecture

```
personal_agent/
â”œâ”€â”€ crt_memory_global_{user_id}.db      # NEW: Cross-thread memories
â”‚   â”œâ”€â”€ memories (memory_id, user_id, slot, value_text, source_thread_id, ...)
â”‚   â””â”€â”€ Same schema as thread DB, but user_id scoped
â”‚
â”œâ”€â”€ crt_memory_{thread_id}.db           # Thread-specific overrides/context
â”‚   â””â”€â”€ memories (memory_id, thread_id, is_global_override, ...)
â”‚
â”œâ”€â”€ crt_ledger_global_{user_id}.db      # NEW: Global contradictions
â”‚   â””â”€â”€ contradictions (...)
â”‚
â””â”€â”€ crt_ledger_{thread_id}.db           # Thread-specific contradictions
    â””â”€â”€ contradictions (...)
```

**Retrieval Logic:**
```python
def retrieve_memories(slot, thread_id, user_id):
    # 1. Check thread-specific memories first (highest priority)
    thread_memories = query_thread_db(slot, thread_id)
    
    # 2. Check global user memories
    global_memories = query_global_db(slot, user_id)
    
    # 3. Merge with conflict resolution
    #    - If thread has explicit override â†’ use thread version
    #    - Otherwise â†’ use global version
    return merge_memories(thread_memories, global_memories)
```

### 3.2 Pros & Cons

| Aspect | Assessment | Details |
|--------|------------|---------|
| **UX Quality** | â˜…â˜…â˜…â˜…â˜† (4/5) | Clean separation enables "this thread only" overrides |
| **Performance** | â˜…â˜…â˜…â˜…â˜† (4/5) | Two queries needed, but both fast (indexed) |
| **Privacy Control** | â˜…â˜…â˜…â˜†â˜† (3/5) | Need explicit "don't promote to global" flag |
| **Implementation** | â˜…â˜…â˜…â˜†â˜† (3/5) | Moderate: two DB systems to maintain |
| **Scalability** | â˜…â˜…â˜…â˜…â˜† (4/5) | Global DB grows slowly (only high-trust facts) |

**Pros:**
- âœ… **Clean Separation** - Global facts vs. thread context explicitly separated
- âœ… **Multi-Device Support** - Global DB enables sync across devices/sessions
- âœ… **Selective Promotion** - Control what becomes "global knowledge"
- âœ… **Thread Override** - "For this conversation, call me by nickname" works naturally
- âœ… **Easy to Understand** - Developers and users can reason about two-tier model

**Cons:**
- âŒ **Two Databases** - Need to query both, maintain both, migrate both
- âŒ **Merge Complexity** - How to resolve when global and thread contradict?
- âŒ **Promotion Logic** - When does thread memory become global? (trust threshold? user approval?)
- âŒ **Demotion Logic** - Can global memory become thread-scoped again?
- âŒ **Migration Effort** - Need to analyze existing threads, consolidate facts

### 3.3 Implementation Complexity

**Schema Changes:** Medium
```sql
-- New global database (same schema as thread DB)
CREATE TABLE memories_global (
    memory_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,             -- NEW: user scoping
    vector_json TEXT NOT NULL,
    text TEXT NOT NULL,
    timestamp REAL NOT NULL,
    confidence REAL NOT NULL,
    trust REAL NOT NULL,
    source TEXT NOT NULL,
    sse_mode TEXT NOT NULL,
    source_thread_id TEXT,             -- NEW: track origin thread
    promoted_timestamp REAL,           -- NEW: when promoted to global
    context_json TEXT,
    tags_json TEXT
);

-- Thread DB adds override flag
ALTER TABLE memories ADD COLUMN is_global_override INTEGER DEFAULT 0;
```

**Code Changes:** Medium
- Modify `CRTMemorySystem.__init__()` to open both DBs
- Modify `retrieve_memories()` to query both and merge
- Add `promote_to_global()` method (when trust > threshold)
- Add `demote_to_thread()` method (if user wants thread-specific)
- Update contradiction detection to check both DBs

**Migration Effort:** High
- Analyze all existing thread DBs
- Identify high-trust memories (trust > 0.85)
- Deduplicate across threads (same fact in multiple threads)
- Promote to global DB
- Handle conflicts (different values in different threads)

**Testing Effort:** High
- Unit tests for merge logic
- Integration tests for two-DB queries
- Performance tests (is 2x query overhead acceptable?)
- Migration tests (data integrity)

### 3.4 Key Trade-offs

1. **Complexity vs. Clarity**
   - PRO: Two DBs are conceptually clear ("global" vs "local")
   - CON: More code paths, more failure modes

2. **Performance vs. Flexibility**
   - PRO: Can optimize global DB separately (different indexes)
   - CON: Two queries = 2x latency (though both should be fast)

3. **User Control vs. Automation**
   - PRO: Users can explicitly manage "global vs thread"
   - CON: Requires UI for promotion/demotion (adds complexity)

### 3.5 Example Scenarios

**Scenario 1: New Thread Start**
```
User starts Thread 42

1. Query global DB: "name=Nick, employer=Google, age=28" (trust=0.9)
2. Thread DB empty (new thread)
3. Retrieval returns global facts
4. User sees: "Hi Nick! How can I help you today?"

Result: âœ… Good UX (remembers from past threads)
```

**Scenario 2: Thread Override**
```
User in Thread 42: "For this conversation, call me Nicholas, not Nick"

1. Store in thread DB: name=Nicholas (is_global_override=1)
2. Query global DB: name=Nick
3. Merge logic sees override flag â†’ use thread version
4. User sees: "Got it, Nicholas!"

Next thread (Thread 43):
1. Query global DB: name=Nick (no override)
2. User sees: "Hi Nick!" (back to global default)

Result: âœ… Scoped override works as expected
```

**Scenario 3: Contradiction Across Threads**
```
Global DB: employer=Microsoft (trust=0.85, 2 weeks ago)
Thread 42: employer=Google (trust=0.9, yesterday)

Option A: Automatically promote Google to global (higher trust + recency)
Option B: Ask user: "Update your profile to Google?"
Option C: Keep both, thread-scoped

Decision: Option B (user control) is safest
```


---

## 4. Option 2: Unified Database with Scoping

### 4.1 Architecture

```
personal_agent/
â””â”€â”€ crt_memory_{user_id}.db  # Single DB for all threads
    â””â”€â”€ memories (
        memory_id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        thread_id TEXT,              -- NULL = global, specific = thread-scoped
        scope TEXT NOT NULL,         -- 'global' or 'thread'
        vector_json TEXT NOT NULL,
        text TEXT NOT NULL,
        timestamp REAL NOT NULL,
        confidence REAL NOT NULL,
        trust REAL NOT NULL,
        source TEXT NOT NULL,
        sse_mode TEXT NOT NULL,
        ...
    )
```

**Retrieval Logic:**
```python
def retrieve_memories(slot, thread_id, user_id):
    conn = sqlite3.connect(f"crt_memory_{user_id}.db")
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT memory_id, vector_json, text, trust, scope
        FROM memories
        WHERE user_id = ?
          AND (scope = 'global' OR thread_id = ?)
          AND deprecated = 0
        ORDER BY 
            CASE WHEN scope = 'thread' THEN 1 ELSE 2 END,  -- Thread first
            trust DESC
    """, (user_id, thread_id))
    
    # Process results with trust-weighted scoring
    return compute_scores(cursor.fetchall(), query)
```

### 4.2 Pros & Cons

| Aspect | Assessment | Details |
|--------|------------|---------|
| **UX Quality** | â˜…â˜…â˜…â˜…â˜… (5/5) | Seamless: all memories in one place |
| **Performance** | â˜…â˜…â˜…â˜…â˜† (4/5) | Single query, but DB grows large over time |
| **Privacy Control** | â˜…â˜…â˜…â˜…â˜† (4/5) | Easy: just set scope='thread' for private memories |
| **Implementation** | â˜…â˜…â˜…â˜…â˜† (4/5) | Relatively simple: one DB, clear schema |
| **Scalability** | â˜…â˜…â˜…â˜†â˜† (3/5) | Single large DB (10K+ memories) needs good indexing |

**Pros:**
- âœ… **Single Source of Truth** - No merge logic needed
- âœ… **Simple Query** - One SQL query gets both global and thread memories
- âœ… **Clear Scoping** - `scope` column is explicit and queryable
- âœ… **Easy Thread Override** - Just insert with `scope='thread'`, higher priority
- âœ… **Atomic Operations** - No need to sync two databases
- âœ… **Simplified Testing** - One database to test, one code path

**Cons:**
- âŒ **Single Large DB** - 500 threads Ã— 50 memories = 25K rows (slower over time)
- âŒ **Thread Deletion Complexity** - Can't just "delete thread DB", need to filter
- âŒ **Scope Ambiguity** - Who decides scope? (user, system, heuristic?)
- âŒ **Index Bloat** - Need indexes on `(user_id, scope, thread_id)` tuple
- âŒ **Privacy Risk** - All threads in one DB (if compromised, all data exposed)

### 4.3 Implementation Complexity

**Schema Changes:** Low-Medium
```sql
-- Modify existing memories table
ALTER TABLE memories ADD COLUMN user_id TEXT;
ALTER TABLE memories ADD COLUMN scope TEXT DEFAULT 'thread';

-- Update thread_id to allow NULL (for global memories)
-- (Already nullable in current schema)

-- Create composite index for fast queries
CREATE INDEX idx_user_scope_thread 
ON memories(user_id, scope, thread_id);

CREATE INDEX idx_user_trust_scope
ON memories(user_id, trust DESC, scope);
```

**Code Changes:** Low
- Modify `CRTMemorySystem.__init__()` to accept `user_id`
- Update `store_memory()` to set `scope` (global vs thread)
- Modify `retrieve_memories()` to filter by `(scope=global OR thread_id=?)`
- Add `promote_to_global()` method (UPDATE scope='thread' SET scope='global')
- Add scope decision logic (heuristic: trust > 0.85 â†’ global)

**Migration Effort:** Medium
- Consolidate all `crt_memory_{thread_id}.db` into one `crt_memory_{user_id}.db`
- Set initial scope based on trust (high trust â†’ global, low trust â†’ thread)
- Deduplicate memories (same text across threads)
- Preserve thread_id for thread-scoped memories

**Testing Effort:** Medium
- Unit tests for scope filtering
- Performance tests (query time with 25K rows)
- Migration validation (no data loss)

### 4.4 Key Trade-offs

1. **Simplicity vs. Scalability**
   - PRO: One DB is simpler to reason about
   - CON: Single DB grows large (need aggressive pruning?)

2. **Privacy vs. Convenience**
   - PRO: Easy to query all user knowledge
   - CON: One breach exposes all threads (vs. per-thread isolation)

3. **Explicit vs. Implicit Scoping**
   - PRO: `scope` column is clear and queryable
   - CON: Need logic to decide scope (not always obvious)

### 4.5 Example Scenarios

**Scenario 1: New Thread with Auto-Promotion**
```
Thread 1: User says "My name is Nick"
1. Store: (thread_id=1, scope='thread', trust=0.85)
2. Background job: trust > 0.85 â†’ UPDATE scope='global'

Thread 2 (later): "What's my name?"
1. Query: SELECT WHERE scope='global' OR thread_id=2
2. Finds: name=Nick (scope='global')
3. Response: "Your name is Nick"

Result: âœ… Auto-promotion based on trust
```

**Scenario 2: Explicit Thread-Only Memory**
```
User in therapy thread: "I'm feeling anxious about work"
1. System tags as sensitive: scope='thread'
2. Store: (thread_id=42, scope='thread', trust=0.7)

User in work thread (later): General work discussion
1. Query: SELECT WHERE scope='global' OR thread_id=99
2. Does NOT find therapy memory (thread_id=42, scope='thread')

Result: âœ… Privacy preserved (sensitive thread isolated)
```

**Scenario 3: Thread Override of Global Fact**
```
Global: name=Nick (scope='global', trust=0.9)
Thread 5: "Call me Nicholas here"
1. Store: name=Nicholas (thread_id=5, scope='thread', trust=0.85)

Query in Thread 5:
1. SELECT WHERE scope='global' OR thread_id=5
2. Finds BOTH: name=Nick (global) and name=Nicholas (thread)
3. Merge logic: thread scope > global scope
4. Returns: Nicholas

Result: âœ… Thread override works (priority order)
```


---

## 5. Option 3: Federated Query Across Thread Databases

### 5.1 Architecture

```
personal_agent/
â”œâ”€â”€ crt_memory_thread_001.db
â”œâ”€â”€ crt_memory_thread_002.db
â”œâ”€â”€ crt_memory_thread_003.db
â”œâ”€â”€ ... (one DB per thread)
â””â”€â”€ thread_registry_{user_id}.json    # Maps user â†’ all their threads
    {
      "user_123": {
        "threads": ["thread_001", "thread_002", "thread_003"],
        "metadata": {...}
      }
    }
```

**Retrieval Logic:**
```python
def retrieve_memories(slot, thread_id, user_id):
    # Load user's thread registry
    with open(f"thread_registry_{user_id}.json") as f:
        registry = json.load(f)
    
    threads = registry[user_id]["threads"]
    
    # Query all threads in parallel (using ThreadPoolExecutor)
    all_memories = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = []
        for tid in threads:
            future = executor.submit(query_thread_db, tid, slot)
            futures.append(future)
        
        for future in as_completed(futures):
            memories = future.result()
            all_memories.extend(memories)
    
    # Deduplicate and rank by trust/recency
    return deduplicate_and_rank(all_memories)
```

### 5.2 Pros & Cons

| Aspect | Assessment | Details |
|--------|------------|---------|
| **UX Quality** | â˜…â˜…â˜…â˜†â˜† (3/5) | Works, but deduplication may be inconsistent |
| **Performance** | â˜…â˜†â˜†â˜†â˜† (1/5) | SLOW: N database connections for N threads |
| **Privacy Control** | â˜…â˜…â˜…â˜…â˜… (5/5) | Perfect: threads physically isolated |
| **Implementation** | â˜…â˜…â˜…â˜…â˜… (5/5) | Minimal changes: just add cross-thread query |
| **Scalability** | â˜…â˜…â˜†â˜†â˜† (2/5) | Degrades badly: 500 threads = 500 DB opens |

**Pros:**
- âœ… **No Schema Changes** - Keep existing per-thread DBs as-is
- âœ… **Easy Rollback** - Can disable federated query anytime
- âœ… **Perfect Privacy** - Threads physically separated (delete thread = delete DB file)
- âœ… **Gradual Migration** - Can enable cross-thread for some users, not others
- âœ… **No Data Consolidation** - No risky migration step

**Cons:**
- âŒ **Terrible Performance** - Opening 100+ DBs for every query is unacceptable
- âŒ **Deduplication Complexity** - "name=Nick" in 50 threads â†’ how to merge?
- âŒ **Contradiction Detection** - Need to compare across all threads (exponential complexity)
- âŒ **Memory Overhead** - N database connections = high RAM usage
- âŒ **File Handle Limits** - OS limits on open files could be hit
- âŒ **Inconsistent Results** - Race conditions if multiple threads queried concurrently

### 5.3 Implementation Complexity

**Schema Changes:** None âœ…

**Code Changes:** Low-Medium
```python
# New method in CRTMemorySystem
def retrieve_memories_federated(self, query, user_id, current_thread_id):
    """Query across all user's threads."""
    # Load registry
    threads = self._get_user_threads(user_id)
    
    # Parallel query (using ThreadPoolExecutor)
    all_memories = []
    for thread_id in threads:
        db_path = f"crt_memory_{thread_id}.db"
        if os.path.exists(db_path):
            memories = self._query_single_thread(db_path, query)
            all_memories.extend(memories)
    
    # Deduplicate
    unique_memories = self._deduplicate_by_text_similarity(all_memories)
    
    # Rank
    return self._rank_by_trust_and_recency(unique_memories)
```

**Migration Effort:** None (just add registry file)

**Testing Effort:** Medium
- Test with 1, 10, 100, 500 threads
- Benchmark query time (will be slow)
- Test deduplication logic
- Test concurrent access

### 5.4 Key Trade-offs

1. **Simplicity vs. Performance**
   - PRO: Conceptually simple (just query all threads)
   - CON: Performance makes it unusable in production

2. **Privacy vs. Usability**
   - PRO: Best privacy (physical separation)
   - CON: Worst UX (slow, inconsistent results)

3. **Migration Risk vs. Performance**
   - PRO: Zero migration risk (no data movement)
   - CON: Performance penalty forever (not fixable without migration)

### 5.5 Example Scenarios

**Scenario 1: Querying 100 Threads**
```
User has 100 threads, asks "What's my name?"

1. Load thread registry (100 thread IDs)
2. Open 100 database connections
3. Query each DB for "name" slot
4. Collect 50 results (name appears in 50 threads)
5. Deduplicate: name=Nick (40 threads), name=Nicholas (10 threads)
6. Pick highest trust: Nick (trust=0.9 avg)

Performance:
- 100 DB opens: ~1000ms
- 100 queries: ~500ms
- Deduplication: ~100ms
Total: ~1600ms (1.6 seconds) âŒ SLOW

Compare to Option 2: ~15ms âœ…
```

**Scenario 2: Contradiction Detection**
```
Need to detect if "employer=Microsoft" contradicts "employer=Google"

1. Query all 100 threads for "employer" slot
2. Find: Microsoft (20 threads), Google (30 threads), Amazon (10 threads)
3. Pairwise comparison: 20Ã—30 + 20Ã—10 + 30Ã—10 = 1100 comparisons
4. Each comparison: semantic similarity + trust comparison
5. Result: Multiple contradictions detected

Performance: ~5000ms (5 seconds) âŒ UNUSABLE
```

**Verdict:** Option 3 is **technically feasible but practically unusable** due to performance.


---

## 6. Option 4: Lazy Migration on Thread Start

### 6.1 Architecture

```
personal_agent/
â”œâ”€â”€ crt_memory_{thread_id}.db        # Thread-specific (independent)
â”œâ”€â”€ crt_memory_pool_{user_id}.db     # Shared pool (high-trust facts)
â””â”€â”€ Migration happens at thread boundaries:
    - Thread start: Copy high-trust facts from pool â†’ thread DB
    - Thread end: Promote high-trust facts from thread â†’ pool
```

**Thread Lifecycle:**
```python
def initialize_thread(thread_id, user_id):
    """Called when user starts new thread."""
    # 1. Create new thread DB
    new_db = f"crt_memory_{thread_id}.db"
    
    # 2. Copy high-confidence global facts from pool
    pool_facts = get_pool_facts(user_id, min_trust=0.85)
    copy_facts_to_thread(pool_facts, new_db)
    
    # User now has "memory" from previous threads
    return new_db

def finalize_thread(thread_id, user_id):
    """Called when thread ends (or periodically)."""
    # 1. Get high-trust facts from this thread
    thread_facts = get_thread_facts(thread_id, min_trust=0.9)
    
    # 2. Promote to pool (with conflict resolution)
    for fact in thread_facts:
        merge_into_pool(fact, user_id)  # â† Deduplication logic here
```

### 6.2 Pros & Cons

| Aspect | Assessment | Details |
|--------|------------|---------|
| **UX Quality** | â˜…â˜…â˜…â˜…â˜† (4/5) | Good: memories available, but may be stale |
| **Performance** | â˜…â˜…â˜…â˜…â˜… (5/5) | Fast: thread DB is independent (no joins) |
| **Privacy Control** | â˜…â˜…â˜…â˜†â˜† (3/5) | Medium: need to mark facts as "don't promote" |
| **Implementation** | â˜…â˜…â˜†â˜†â˜† (2/5) | Complex: promotion logic, conflict resolution |
| **Scalability** | â˜…â˜…â˜…â˜…â˜† (4/5) | Good: thread DBs stay small (only copied facts) |

**Pros:**
- âœ… **Thread Independence** - Each thread operates on its own DB (fast queries)
- âœ… **No Cross-DB Queries** - Retrieval is single-DB lookup (like current system)
- âœ… **Natural Import/Export** - Users understand "copy from profile" model
- âœ… **User Control** - Can review facts before promoting to pool
- âœ… **Failure Isolation** - Pool corruption doesn't break threads

**Cons:**
- âŒ **Stale Data** - Thread 1 doesn't see updates from Thread 2 (mid-conversation)
- âŒ **Duplication** - Same fact exists in pool + multiple thread DBs
- âŒ **Complex Promotion** - When to promote? (end of thread? after each message? manual?)
- âŒ **Conflict Resolution** - What if pool has "employer=Microsoft" but thread has "employer=Google"?
- âŒ **Storage Waste** - 100 threads Ã— 50 facts = 5000 duplicated rows

### 6.3 Implementation Complexity

**Schema Changes:** Low
```sql
-- Pool database (similar to thread DB)
CREATE TABLE memory_pool (
    memory_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    vector_json TEXT NOT NULL,
    text TEXT NOT NULL,
    timestamp REAL NOT NULL,
    confidence REAL NOT NULL,
    trust REAL NOT NULL,
    source TEXT NOT NULL,
    source_thread_id TEXT,           -- NEW: track where it came from
    promotion_timestamp REAL,        -- NEW: when promoted
    promotion_count INTEGER DEFAULT 1 -- NEW: how many threads promoted it
);

-- Thread DB adds promotion flag
ALTER TABLE memories ADD COLUMN promoted_to_pool INTEGER DEFAULT 0;
```

**Code Changes:** Medium-High
```python
class ThreadLifecycleManager:
    def start_thread(self, thread_id, user_id):
        """Copy pool facts to new thread."""
        pool = self._load_pool_facts(user_id, min_trust=0.85)
        thread_db = f"crt_memory_{thread_id}.db"
        
        for fact in pool:
            self._copy_to_thread(fact, thread_db)
        
        return thread_db
    
    def end_thread(self, thread_id, user_id):
        """Promote high-trust facts to pool."""
        thread_facts = self._load_thread_facts(thread_id, min_trust=0.9)
        
        for fact in thread_facts:
            # Check if already in pool
            existing = self._find_in_pool(fact, user_id)
            
            if existing:
                # Merge: boost trust, update text if newer
                self._merge_pool_fact(existing, fact)
            else:
                # New fact: add to pool
                self._add_to_pool(fact, user_id, thread_id)
```

**Migration Effort:** Medium
- Create initial pool from high-trust memories across all threads
- Deduplicate (same fact in multiple threads â†’ single pool entry)
- Set `promotion_count` based on how many threads had the fact

**Testing Effort:** High
- Test promotion logic (when to promote?)
- Test conflict resolution (different values in pool vs thread)
- Test staleness scenarios (Thread A updates fact, does Thread B see it?)
- Test storage efficiency (duplication overhead)

### 6.4 Key Trade-offs

1. **Performance vs. Freshness**
   - PRO: Fast queries (single-DB lookup)
   - CON: Stale data (Thread B doesn't see Thread A's updates)

2. **Independence vs. Sync Complexity**
   - PRO: Threads are independent (failure isolation)
   - CON: Complex sync logic (when? how? conflict resolution?)

3. **User Control vs. Automation**
   - PRO: User can review before promoting
   - CON: Adds UX complexity (manual promotion step?)

### 6.5 Example Scenarios

**Scenario 1: Thread Start (Happy Path)**
```
User starts Thread 5

1. Load pool: name=Nick, employer=Google, age=28 (trust=0.9)
2. Copy to Thread 5 DB
3. User asks "What's my name?"
4. Query Thread 5 DB â†’ finds name=Nick
5. Response: "Your name is Nick"

Result: âœ… Memories available from start
```

**Scenario 2: Stale Data Problem**
```
Thread A (running): User says "I switched jobs to Amazon"
1. Store in Thread A DB: employer=Amazon (trust=0.85)
2. NOT promoted yet (thread still active)

Thread B (user opens in parallel): "Where do I work?"
1. Thread B was initialized earlier with pool fact: employer=Google
2. Query Thread B DB â†’ finds employer=Google (STALE)
3. Response: "You work at Google" âŒ WRONG

Problem: Thread B doesn't see Thread A's update
```

**Scenario 3: Promotion Conflict**
```
Pool: employer=Microsoft (trust=0.9, 1 week ago)
Thread 10 ends: employer=Google (trust=0.95, yesterday)

Promotion logic options:
A. Latest wins â†’ Update pool to Google
B. Highest trust wins â†’ Update pool to Google (same result)
C. Ask user â†’ "Update profile: Microsoft â†’ Google?" âœ… Safest
D. Keep both â†’ Store as contradiction in pool ledger
```

**Verdict:** Option 4 is **fast but complex**, with staleness as a major UX issue.


---

## 7. Option 5: Hybrid Profile + Thread Context â­ RECOMMENDED

### 7.1 Architecture

```
personal_agent/
â”œâ”€â”€ user_profile_{user_id}.db           # Stable, high-trust facts
â”‚   â””â”€â”€ profile_facts (
â”‚       fact_id TEXT PRIMARY KEY,
â”‚       user_id TEXT NOT NULL,
â”‚       slot TEXT NOT NULL,             -- name, employer, age, preferences, etc.
â”‚       value_text TEXT NOT NULL,
â”‚       trust REAL NOT NULL,
â”‚       confidence REAL NOT NULL,
â”‚       last_verified REAL,             -- When user last confirmed
â”‚       source_thread_id TEXT,          -- Where it originated
â”‚       vector_json TEXT,
â”‚       metadata_json TEXT
â”‚   )
â”‚
â”œâ”€â”€ crt_memory_{thread_id}.db           # Thread-specific context
â”‚   â””â”€â”€ memories (
â”‚       memory_id TEXT PRIMARY KEY,
â”‚       thread_id TEXT NOT NULL,
â”‚       is_profile_override INTEGER DEFAULT 0,  -- NEW flag
â”‚       profile_fact_id TEXT,                    -- NEW: link to profile
â”‚       ... (existing schema)
â”‚   )
â”‚
â””â”€â”€ Retrieval prioritizes: Thread Override > Profile > Thread Context
```

**Key Insight:** Separate **stable facts** (profile) from **ephemeral context** (thread memories).

### 7.2 Profile-Worthy Slots

**Stable Facts (go in profile):**
- âœ… `name` - "My name is Nick"
- âœ… `employer` - "I work at Google"
- âœ… `location` - "I live in Seattle"
- âœ… `age` - "I'm 28 years old"
- âœ… `preferences` - "I prefer Python over JavaScript"
- âœ… `interests` - "I enjoy hiking and photography"
- âœ… `constraints` - "I'm vegetarian"

**Ephemeral Context (stays in thread):**
- âŒ `current_mood` - "I'm feeling stressed today"
- âŒ `current_task` - "I'm working on a bug fix"
- âŒ `recent_events` - "I just had a meeting"
- âŒ `conversation_context` - "As we discussed earlier..."

**Heuristic:** If it's true **across conversations**, it's profile-worthy.

### 7.3 Retrieval Logic

```python
def retrieve_memories(self, query, thread_id, user_id):
    """Hybrid retrieval: Profile + Thread context."""
    
    # 1. Extract fact slots from query
    slots = extract_fact_slots(query)  # e.g., ["name", "employer"]
    
    # 2. Check thread for explicit overrides
    thread_overrides = {}
    for slot in slots:
        override = self._query_thread_override(thread_id, slot)
        if override:
            thread_overrides[slot] = override
    
    # 3. Check profile for stable facts
    profile_facts = {}
    for slot in slots:
        if slot not in thread_overrides:  # Skip if thread override exists
            fact = self._query_profile(user_id, slot)
            if fact:
                profile_facts[slot] = fact
    
    # 4. Check thread memories (non-profile context)
    thread_context = self._query_thread_memories(thread_id, query)
    
    # 5. Merge: Thread Override > Profile > Thread Context
    return {
        **thread_context,      # Lowest priority
        **profile_facts,       # Medium priority
        **thread_overrides     # Highest priority
    }
```

### 7.4 Pros & Cons

| Aspect | Assessment | Details |
|--------|------------|---------|
| **UX Quality** | â˜…â˜…â˜…â˜…â˜… (5/5) | Natural: users understand "profile" concept |
| **Performance** | â˜…â˜…â˜…â˜…â˜… (5/5) | Fast: profile is small (~100 facts), indexed |
| **Privacy Control** | â˜…â˜…â˜…â˜…â˜† (4/5) | Good: profile separate from sensitive threads |
| **Implementation** | â˜…â˜…â˜…â˜†â˜† (3/5) | Moderate: new profile DB + classification logic |
| **Scalability** | â˜…â˜…â˜…â˜…â˜… (5/5) | Excellent: profile grows slowly, threads stay small |

**Pros:**
- âœ… **Clear Separation** - Stable vs ephemeral is intuitive (users + developers)
- âœ… **Fast Queries** - Profile is tiny (~100 facts), threads small (~50 facts)
- âœ… **Natural UX** - Aligns with user mental model ("my profile" vs "this conversation")
- âœ… **Easy UI** - Can show users "Your Profile" page (name, job, preferences)
- âœ… **Privacy Control** - Profile is separate from thread-specific sensitive data
- âœ… **Industry Alignment** - Matches patterns in agent-zero, LangChain, ChatGPT
- âœ… **Selective Sync** - Profile can sync across devices, threads stay local

**Cons:**
- âŒ **Classification Logic** - Need to decide what's "profile-worthy" (heuristic or ML?)
- âŒ **Profile Bloat** - What if everything becomes "profile"? (need constraints)
- âŒ **Sync Timing** - When to update profile from thread? (manual? automatic?)
- âŒ **Contradiction Handling** - Thread says "employer=Google", profile says "employer=Microsoft"

### 7.5 Implementation Complexity

**Schema Changes:** Medium
```sql
-- New profile database
CREATE TABLE profile_facts (
    fact_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    slot TEXT NOT NULL,              -- Fact category (name, employer, age, ...)
    value_text TEXT NOT NULL,
    trust REAL NOT NULL,
    confidence REAL NOT NULL,
    last_verified REAL,              -- When user last confirmed this fact
    source_thread_id TEXT,           -- Where it originated
    vector_json TEXT,                -- Semantic embedding
    metadata_json TEXT,
    created_at REAL NOT NULL,
    updated_at REAL NOT NULL
);

CREATE INDEX idx_profile_user_slot ON profile_facts(user_id, slot);
CREATE INDEX idx_profile_trust ON profile_facts(trust DESC);

-- Thread DB modifications
ALTER TABLE memories ADD COLUMN is_profile_override INTEGER DEFAULT 0;
ALTER TABLE memories ADD COLUMN profile_fact_id TEXT;  -- Link to profile fact
```

**Code Changes:** Medium
```python
class UserProfile:
    """Manages user profile (stable facts)."""
    
    def __init__(self, user_id):
        self.db_path = f"user_profile_{user_id}.db"
        self._init_db()
    
    def get_fact(self, slot):
        """Get profile fact by slot."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT fact_id, value_text, trust, vector_json
            FROM profile_facts
            WHERE user_id = ? AND slot = ?
            ORDER BY trust DESC
            LIMIT 1
        """, (self.user_id, slot))
        return cursor.fetchone()
    
    def update_fact(self, slot, value, trust, source_thread_id):
        """Update or insert profile fact."""
        existing = self.get_fact(slot)
        
        if existing:
            # Check if this is a contradiction
            if existing['value_text'] != value:
                # Create contradiction entry, ask user to resolve
                self._create_profile_contradiction(existing, value, source_thread_id)
            else:
                # Reinforce: boost trust
                self._boost_trust(existing['fact_id'], trust)
        else:
            # New fact: insert
            self._insert_fact(slot, value, trust, source_thread_id)

class CRTEnhancedRAG:
    def retrieve_memories(self, query, thread_id, user_id):
        """Hybrid retrieval."""
        # Extract slots
        slots = extract_fact_slots(query)
        
        # Check profile
        profile_facts = []
        for slot in slots:
            fact = self.user_profile.get_fact(slot)
            if fact:
                profile_facts.append(fact)
        
        # Check thread (with override check)
        thread_memories = self.memory.retrieve_memories(
            query, thread_id, exclude_profile_duplicates=True
        )
        
        # Merge (thread overrides > profile > thread context)
        return self._merge_hybrid_results(profile_facts, thread_memories)
```

**Migration Effort:** Medium
- Analyze all threads, identify high-trust, profile-worthy facts
- Extract facts into profile DB (deduplicate across threads)
- Link thread memories to profile facts (for override tracking)
- Create profile UI (optional but recommended)

**Testing Effort:** Medium
- Test profile extraction (which facts are profile-worthy?)
- Test override logic (thread overrides profile)
- Test contradiction detection (profile vs thread conflict)
- Test profile sync (update from thread)

### 7.6 Key Trade-offs

1. **Clarity vs. Classification Effort**
   - PRO: Very clear separation (users + devs understand it)
   - CON: Need logic to classify facts as profile/context

2. **Performance vs. Duplication**
   - PRO: Excellent performance (small profile + small thread DBs)
   - CON: Some duplication (profile fact + thread reference)

3. **User Control vs. Automation**
   - PRO: Can build "profile management" UI (user control)
   - CON: Need sync logic (when to update profile from thread?)

### 7.7 Example Scenarios

**Scenario 1: New Thread with Profile**
```
User starts Thread 10

1. Query profile: name=Nick, employer=Google, age=28
2. Thread DB empty (new thread)
3. User asks "What's my name?"
4. Retrieval: Check thread override (none) â†’ Check profile (Nick) â†’ Return
5. Response: "Your name is Nick"

Result: âœ… Instant memory from profile
```

**Scenario 2: Thread Override**
```
User in casual thread: "Call me Nicky in this chat"

1. Store in thread: name=Nicky (is_profile_override=1)
2. Query: Check thread override (Nicky) â†’ Skip profile â†’ Return Nicky
3. Response: "Got it, Nicky!"

Next thread:
1. No override â†’ Check profile (Nick) â†’ Return Nick
2. Response: "Hi Nick!"

Result: âœ… Scoped override works
```

**Scenario 3: Profile Update from Thread**
```
Thread 15: "I got promoted to Senior Engineer"

1. Store in thread: title=Senior Engineer (trust=0.85)
2. Background job detects profile-worthy fact (title is stable)
3. Check profile: title=Software Engineer
4. Contradiction detected â†’ Ask user
5. User confirms â†’ Update profile: title=Senior Engineer
6. Future threads see updated profile

Result: âœ… Profile evolves with user's life
```

**Scenario 4: Privacy Protection**
```
User in therapy thread (Thread 99): "I'm struggling with anxiety"

1. Store in thread: mental_health=anxiety (trust=0.7)
2. Classification: mental_health is NOT profile-worthy (ephemeral + sensitive)
3. Stays in thread only (not promoted to profile)

Work thread (Thread 100): General work discussion
1. Query profile: name=Nick, employer=Google (no mental_health fact)
2. Query Thread 100 memories (no mental_health)
3. Response does NOT reference anxiety

Result: âœ… Sensitive data stays thread-isolated
```

### 7.8 Profile-Worthy Classification Logic

**Heuristic-Based (Phase 1):**
```python
PROFILE_SLOTS = {
    "name", "employer", "location", "age", "education",
    "preferences", "interests", "constraints", "expertise"
}

def is_profile_worthy(slot, trust, confidence):
    """Determine if memory should go in profile."""
    if slot in PROFILE_SLOTS and trust > 0.85:
        return True
    return False
```

**ML-Based (Phase 2 - Future):**
- Train classifier on (memory_text, slot, trust) â†’ profile_worthy (yes/no)
- Features: slot type, trust, confidence, user confirmation count
- Model: Logistic regression or simple neural net

### 7.9 Comparison with agent-zero

**agent-zero Pattern (from reference):**
```python
# agent-zero uses memory "areas" (similar to our slots)
Memory.Area.MAIN = "main"           # Similar to our profile
Memory.Area.FRAGMENTS = "fragments" # Similar to our thread context
Memory.Area.SOLUTIONS = "solutions" # Task-specific (not needed for us)

# They use subdirectories per agent (similar to our thread_id)
memory_subdir = get_agent_memory_subdir(agent)
```

**Our adaptation:**
- Profile = "MAIN area" (cross-thread, stable)
- Thread memories = "FRAGMENTS area" (ephemeral, context)
- Slot-based instead of area-based (more structured)

**Verdict:** Option 5 aligns with proven patterns (agent-zero) while adding CRT-specific trust/confidence tracking.


---

## 8. Comparison Matrix

### 8.1 Overall Ratings

| Criteria | Option 1<br/>Global DB | Option 2<br/>Unified | Option 3<br/>Federated | Option 4<br/>Lazy Copy | Option 5<br/>Hybrid â­ |
|----------|------------|----------|------------|----------|-----------|
| **UX Quality** | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜… (5/5) | â˜…â˜…â˜…â˜†â˜† (3/5) | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜… (5/5) |
| **Performance** | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜†â˜†â˜†â˜† (1/5) | â˜…â˜…â˜…â˜…â˜… (5/5) | â˜…â˜…â˜…â˜…â˜… (5/5) |
| **Privacy Control** | â˜…â˜…â˜…â˜†â˜† (3/5) | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜… (5/5) | â˜…â˜…â˜…â˜†â˜† (3/5) | â˜…â˜…â˜…â˜…â˜† (4/5) |
| **Implementation** | â˜…â˜…â˜…â˜†â˜† (3/5) | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜… (5/5) | â˜…â˜…â˜†â˜†â˜† (2/5) | â˜…â˜…â˜…â˜†â˜† (3/5) |
| **Scalability** | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜†â˜† (3/5) | â˜…â˜…â˜†â˜†â˜† (2/5) | â˜…â˜…â˜…â˜…â˜† (4/5) | â˜…â˜…â˜…â˜…â˜… (5/5) |
| **TOTAL** | **18/25** | **20/25** | **16/25** | **18/25** | **22/25** â­ |

### 8.2 Detailed Comparison

#### Query Performance (1K Memories)

| Option | Single Query | 10 Queries | Notes |
|--------|-------------|------------|-------|
| Option 1 | ~15ms | ~150ms | Two DB queries (global + thread) |
| Option 2 | ~12ms | ~120ms | Single query, but larger DB |
| Option 3 | ~1500ms | ~15000ms | N database opens (unusable) |
| Option 4 | ~8ms | ~80ms | Fast (single thread DB), but stale data |
| Option 5 | ~10ms | ~100ms | Profile + thread (both small DBs) |

**Winner:** Option 5 (balanced speed + freshness)

#### Storage Efficiency (500 Threads, 50 Memories Each)

| Option | Total Rows | Duplication | Storage Size |
|--------|-----------|-------------|--------------|
| Option 1 | ~5000 + ~20000 = 25K | Low (global deduplicated) | ~500 MB |
| Option 2 | ~25K | None (single DB) | ~450 MB |
| Option 3 | ~25K | High (same fact in many threads) | ~700 MB |
| Option 4 | ~5000 (pool) + ~25K (threads) = 30K | Very High | ~800 MB |
| Option 5 | ~100 (profile) + ~24K (threads) = 24.1K | Very Low | ~400 MB |

**Winner:** Option 5 (smallest storage, minimal duplication)

#### Privacy Isolation

| Option | Thread Deletion | Sensitive Data Leak Risk | User Control |
|--------|----------------|------------------------|--------------|
| Option 1 | Delete thread DB file | Medium (global may have thread data) | Explicit promotion |
| Option 2 | DELETE WHERE thread_id=? | Higher (all in one DB) | Scope flag |
| Option 3 | Delete thread DB file | Lowest (physical isolation) | Perfect |
| Option 4 | Delete thread DB + pool entry | Medium (pool has thread data) | Review before promote |
| Option 5 | Delete thread DB file | Low (profile separate) | Profile is explicit |

**Winner:** Option 3 (but impractical due to performance)  
**Practical Winner:** Option 5 (good balance)

#### Migration Complexity

| Option | Schema Changes | Data Movement | Rollback Difficulty |
|--------|----------------|--------------|---------------------|
| Option 1 | Medium (new global DB) | High (consolidate threads) | Medium |
| Option 2 | Low (add columns) | High (merge threads) | Hard (can't split DB) |
| Option 3 | None | None | Easy (just disable) |
| Option 4 | Medium (pool DB) | Medium (extract to pool) | Medium |
| Option 5 | Medium (profile DB) | Medium (extract profile facts) | Easy (profile is separate) |

**Winner:** Option 3 (but impractical)  
**Practical Winner:** Option 5 (clean separation enables easy rollback)

### 8.3 Decision Matrix by Use Case

**If you prioritize...**

| Priority | Best Option | Why |
|----------|------------|-----|
| **Fast Queries** | Option 5 | Small profile + thread DBs = fast lookups |
| **Simple Implementation** | Option 3 | No schema changes (but poor performance) |
| **Privacy Control** | Option 3 or 5 | Physical separation or profile isolation |
| **User Experience** | Option 2 or 5 | Seamless memory across threads |
| **Scalability** | Option 5 | Profile grows slowly, threads stay small |
| **Migration Safety** | Option 3 | No data movement required |

**Overall Winner:** **Option 5 (Hybrid)** - Best balance across all dimensions


---

## 9. Contradiction Handling Strategy

### 9.1 Core Scenarios

**Case 1: Same Fact, Different Values**
```
Thread A: name=Nick
Thread B: name=Nicholas
```

**Resolution Strategies:**

| Strategy | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|----------|----------|----------|----------|----------|----------|
| **Latest Wins** | Global updated | Scope priority | Dedup picks latest | Pool updated | Profile updated |
| **Highest Trust** | Compare trust | Compare trust | Dedup picks highest trust | Pool picks highest trust | Profile picks highest trust |
| **Ask User** | âœ… Best | âœ… Best | âŒ Too complex | âœ… On promotion | âœ… Best |
| **Keep Both** | Ledger entry | Ledger entry | âŒ Confusing | âŒ Wastes space | Ledger entry |

**Recommended for all options:** **Ask User** with **Highest Trust** as fallback

---

**Case 2: Timeline Conflicts**
```
Thread A (Jan 1):  employer=Microsoft
Thread B (Jan 15): employer=Google
```

**Analysis:**
- This could be a job change (valid update)
- Or a contradiction (user works at both?)
- Or an error (misheard)

**Resolution:**

| Option | Handling | User Experience |
|--------|----------|-----------------|
| Option 1 | Global tracks timestamp, shows "Microsoft â†’ Google" | Clear timeline |
| Option 2 | Both stored, scope + timestamp used | Both visible |
| Option 3 | Dedup by recency | Latest only (may lose history) |
| Option 4 | Pool updated on promotion | Latest after promotion |
| Option 5 | Profile shows latest, ledger tracks change | âœ… Best: current + history |

**Recommended:** Option 5 - Profile shows current, ledger preserves history

---

**Case 3: Confidence Conflicts**
```
Thread A: age=28 (trust=0.9, confidence=0.95)
Thread B: age=29 (trust=0.7, confidence=0.6)
```

**Trust-Based Resolution:**
```python
def resolve_contradiction(fact_a, fact_b):
    """Resolve using trust-weighted scoring."""
    
    # Option A: Pure trust
    if fact_a.trust > fact_b.trust:
        return fact_a
    
    # Option B: Trust + Confidence + Recency
    score_a = (
        0.6 * fact_a.trust +
        0.2 * fact_a.confidence +
        0.2 * recency_weight(fact_a.timestamp)
    )
    score_b = (
        0.6 * fact_b.trust +
        0.2 * fact_b.confidence +
        0.2 * recency_weight(fact_b.timestamp)
    )
    
    if abs(score_a - score_b) < 0.1:
        # Too close to call â†’ Ask user
        return ask_user_to_resolve(fact_a, fact_b)
    
    return fact_a if score_a > score_b else fact_b
```

**Recommended:** Trust-weighted scoring with user confirmation for close calls

### 9.2 Contradiction Detection Across Threads

**Challenge:** How to detect that "employer=Microsoft" in Thread 1 contradicts "employer=Google" in Thread 2?

**Approaches:**

| Approach | When | Cost | Accuracy |
|----------|------|------|----------|
| **On Query** | When retrieving memories | Low (only query-relevant facts) | High |
| **On Write** | When storing new memory | Medium (check all threads) | High |
| **Background Job** | Periodic (e.g., nightly) | Low (amortized) | Medium |
| **On Promotion** | When promoting to global/profile | Low (only promoted facts) | High |

**Recommended:** **On Promotion** (Option 5) - Check contradictions only when fact is promoted to profile

**Implementation (Option 5):**
```python
def promote_to_profile(memory, user_id):
    """Promote thread memory to profile with contradiction check."""
    
    # Extract slot
    slot = extract_slot_from_memory(memory)
    
    # Check existing profile fact
    existing = user_profile.get_fact(user_id, slot)
    
    if existing:
        # Check for contradiction
        if are_contradictory(existing.value, memory.text):
            # Create contradiction entry
            contradiction = ContradictionEntry(
                old_memory_id=existing.fact_id,
                new_memory_id=memory.memory_id,
                drift_mean=compute_drift(existing, memory),
                status=ContradictionStatus.OPEN
            )
            ledger.store_contradiction(contradiction)
            
            # Ask user to resolve
            resolution = ask_user_to_resolve(existing, memory)
            
            if resolution == "keep_new":
                user_profile.update_fact(slot, memory.text, memory.trust)
                ledger.update_status(contradiction.ledger_id, ContradictionStatus.RESOLVED)
            elif resolution == "keep_old":
                # Keep existing, don't promote
                pass
            elif resolution == "merge":
                # User provides merged value
                merged_value = user_provides_merged_value()
                user_profile.update_fact(slot, merged_value, max(existing.trust, memory.trust))
                ledger.update_status(contradiction.ledger_id, ContradictionStatus.RESOLVED)
        else:
            # No contradiction, just reinforce trust
            user_profile.boost_trust(existing.fact_id, memory.trust)
    else:
        # New fact, add to profile
        user_profile.add_fact(slot, memory.text, memory.trust, memory.thread_id)
```

### 9.3 CRT Ledger Integration

**Current Ledger (Per-Thread):**
```
crt_ledger_{thread_id}.db
â””â”€â”€ contradictions (ledger_id, old_memory_id, new_memory_id, status, ...)
```

**Enhanced Ledger (Option 5):**
```
crt_ledger_profile_{user_id}.db  # NEW: Profile-level contradictions
â””â”€â”€ profile_contradictions (
    ledger_id TEXT PRIMARY KEY,
    old_fact_id TEXT,            -- Profile fact ID
    new_memory_id TEXT,          -- Thread memory ID
    source_thread_id TEXT,       -- Which thread caused contradiction
    drift_mean REAL,
    status TEXT,                 -- open, resolved, accepted
    resolution_method TEXT,      -- user_choice, trust_based, timeline
    ...
)
```

**Advantage:** Contradictions tracked at profile level, visible across all threads


---

## 10. Privacy Assessment

### 10.1 Data Leakage Risks

**Scenario:** User has private therapy thread, should NOT leak into work thread

| Option | Leakage Risk | Why | Mitigation |
|--------|--------------|-----|------------|
| **Option 1** | Medium | Global DB may have therapy facts if auto-promoted | Don't auto-promote sensitive slots |
| **Option 2** | Higher | All threads in one DB, scope filtering critical | Explicit `scope='thread'` for sensitive |
| **Option 3** | Lowest | Physical isolation per thread | Works by default |
| **Option 4** | Medium | Pool may have therapy facts if promoted | Review before promotion |
| **Option 5** | Low | Profile separate from threads, sensitive stays in thread | âœ… Profile-worthy heuristic excludes sensitive |

**Sensitive Slots (Never Profile-Worthy):**
```python
SENSITIVE_SLOTS = {
    "mental_health",
    "medical_condition",
    "financial_details",
    "personal_relationships",
    "legal_issues",
    "passwords",  # Obviously
    "api_keys",   # Obviously
}

def is_sensitive(slot):
    """Check if slot contains sensitive data."""
    return slot in SENSITIVE_SLOTS
```

### 10.2 User Control Mechanisms

**What Users Should Be Able To Do:**

| Capability | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|------------|----------|----------|----------|----------|----------|
| View all cross-thread memories | âœ… Query global DB | âœ… Query scope='global' | âŒ Hard (N DBs) | âœ… Query pool | âœ… View profile |
| Delete specific memory globally | âœ… Delete from global | âœ… Delete row | âŒ Delete from all threads | âœ… Delete from pool | âœ… Delete from profile |
| Mark thread as "don't share" | âœ… Flag "no promote" | âœ… Set scope='thread' | âœ… Works by default | âœ… Flag "no promote" | âœ… Don't extract to profile |
| Manual promote to global | âœ… User action | âœ… UPDATE scope | âŒ Complex | âœ… Copy to pool | âœ… Add to profile |
| See provenance | âœ… source_thread_id | âŒ Hard to track | âœ… Per-thread DBs | âœ… source_thread_id | âœ… source_thread_id |

**Recommended UI (Option 5):**
```
User Profile Page:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your Profile                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Name: Nick                              â”‚
â”‚   Last verified: 2 days ago (Thread 42) â”‚
â”‚   [Edit] [Remove from profile]          â”‚
â”‚                                         â”‚
â”‚ Employer: Google                        â”‚
â”‚   Last verified: Yesterday (Thread 45)  â”‚
â”‚   [Edit] [Remove from profile]          â”‚
â”‚                                         â”‚
â”‚ Location: Seattle                       â”‚
â”‚   Last verified: 1 week ago (Thread 38) â”‚
â”‚   [Edit] [Remove from profile]          â”‚
â”‚                                         â”‚
â”‚ [+ Add fact to profile]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Thread Settings:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Thread Privacy Settings                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â˜ Private thread (don't share facts)   â”‚
â”‚ â˜ Auto-promote high-trust facts         â”‚
â”‚ â˜‘ Ask before promoting to profile       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.3 GDPR Compliance

**Right to Deletion:**

| Requirement | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|-------------|----------|----------|----------|----------|----------|
| Delete all user data | Delete global + all thread DBs | DELETE WHERE user_id=? | Delete all thread DB files | Delete pool + all thread DBs | Delete profile + all thread DBs |
| Delete specific fact | DELETE from global + threads | DELETE WHERE fact=? | Search N DBs, delete | DELETE from pool + threads | DELETE from profile + threads |
| Export all data | Query global + threads â†’ JSON | Query all â†’ JSON | Query N DBs â†’ JSON | Query pool + threads â†’ JSON | Query profile + threads â†’ JSON |

**Winner:** Option 2 (single DB makes deletion easy) or Option 5 (small profile easy to export)

**Recommended (Option 5):**
```python
def export_user_data(user_id):
    """Export all user data (GDPR compliance)."""
    
    # Export profile
    profile_data = user_profile.export_all_facts(user_id)
    
    # Export all threads
    threads = get_user_threads(user_id)
    thread_data = []
    for thread_id in threads:
        thread_memories = memory_system.export_thread(thread_id)
        thread_data.append({
            "thread_id": thread_id,
            "memories": thread_memories
        })
    
    return {
        "user_id": user_id,
        "profile": profile_data,
        "threads": thread_data,
        "export_timestamp": time.time()
    }

def delete_user_data(user_id):
    """Delete all user data (GDPR compliance)."""
    
    # Delete profile
    os.remove(f"user_profile_{user_id}.db")
    
    # Delete all threads
    threads = get_user_threads(user_id)
    for thread_id in threads:
        os.remove(f"crt_memory_{thread_id}.db")
        os.remove(f"crt_ledger_{thread_id}.db")
    
    # Delete registry
    registry = load_registry()
    del registry[user_id]
    save_registry(registry)
```

### 10.4 Privacy Recommendations

**For Option 5 (Recommended):**

1. **Sensitive Slot Detection** - Automatically detect sensitive data types, never promote to profile
2. **User Confirmation** - Always ask before promoting facts to profile (unless user enables auto-promote)
3. **Thread Privacy Flag** - Allow users to mark entire threads as private (no profile extraction)
4. **Profile Audit Log** - Track all changes to profile (who, when, from which thread)
5. **Granular Export** - Support exporting profile separately from threads

**Implementation:**
```python
# Privacy settings per user
class PrivacySettings:
    auto_promote_to_profile: bool = False      # Require confirmation
    private_thread_ids: Set[str] = set()       # Threads marked private
    blocked_profile_slots: Set[str] = set()    # Slots user doesn't want in profile
    
def should_promote_to_profile(memory, thread_id, user_id):
    """Check if memory should be promoted to profile."""
    settings = get_privacy_settings(user_id)
    
    # Check thread privacy
    if thread_id in settings.private_thread_ids:
        return False
    
    # Check sensitive slots
    slot = extract_slot(memory)
    if is_sensitive(slot):
        return False
    
    # Check user blocks
    if slot in settings.blocked_profile_slots:
        return False
    
    # Check profile-worthiness
    if not is_profile_worthy(slot, memory.trust):
        return False
    
    # If auto-promote enabled, go ahead
    if settings.auto_promote_to_profile:
        return True
    
    # Otherwise, ask user
    return ask_user_permission(memory, user_id)
```


---

## 11. Performance Benchmarks

### 11.1 Benchmark Setup

**Test Scenarios:**
- Users: 1 (single-user testing)
- Threads per user: [1, 10, 100, 500]
- Memories per thread: [10, 50, 100]
- Profile facts (Option 5): 100

**Operations Measured:**
1. **Single Fact Retrieval** - "What's my name?"
2. **Multi-Fact Retrieval** - "Tell me about myself" (10 facts)
3. **Write New Memory** - Store new fact
4. **Contradiction Detection** - Check for conflicts

### 11.2 Estimated Performance (Query Time in ms)

#### Single Fact Retrieval ("What's my name?")

| Threads | Option 1<br/>Global | Option 2<br/>Unified | Option 3<br/>Federated | Option 4<br/>Lazy | Option 5<br/>Hybrid |
|---------|----------|----------|------------|----------|-----------|
| 1 | 8ms | 10ms | 50ms | 5ms | 8ms |
| 10 | 10ms | 12ms | 500ms | 5ms | 8ms |
| 100 | 15ms | 18ms | 5000ms | 5ms | 10ms |
| 500 | 25ms | 35ms | 25000ms | 5ms | 12ms |

**Analysis:**
- **Option 3** degrades catastrophically with thread count (unusable at scale)
- **Option 4** fastest but may return stale data
- **Option 5** maintains consistent performance (profile + thread both small)

---

#### Multi-Fact Retrieval (10 facts)

| Threads | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|---------|----------|----------|----------|----------|----------|
| 1 | 15ms | 18ms | 100ms | 8ms | 12ms |
| 10 | 20ms | 25ms | 1000ms | 8ms | 15ms |
| 100 | 35ms | 50ms | 10000ms | 8ms | 20ms |
| 500 | 60ms | 120ms | 50000ms | 8ms | 25ms |

**Winner:** Option 5 (fast + fresh data)

---

#### Write Performance (new memory)

| Threads | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|---------|----------|----------|----------|----------|----------|
| 1 | 5ms | 5ms | 5ms | 5ms | 5ms |
| 100 | 8ms | 12ms | 5ms | 5ms | 8ms |
| 500 | 12ms | 25ms | 5ms | 5ms | 10ms |

**Analysis:**
- **Write performance** relatively similar (small differences)
- **Option 2** slower with large DB (need to index on write)
- **Option 5** maintains fast writes (thread DB is small)

---

#### Contradiction Detection (cross-thread)

| Threads | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|---------|----------|----------|----------|----------|----------|
| 10 | 50ms | 30ms | 5000ms | 100ms | 20ms |
| 100 | 200ms | 150ms | 50000ms | 1000ms | 50ms |
| 500 | 500ms | 800ms | 250000ms | 5000ms | 100ms |

**Analysis:**
- **Option 5 wins**: Only check profile (100 facts) vs. thread memory, not all threads
- **Option 3 fails**: Need to compare across N threads (exponential complexity)

### 11.3 Storage Efficiency

**Scenario: 500 threads, 50 memories/thread, 100 profile facts**

| Option | Total Rows | Duplication | DB Size | Index Size | Total |
|--------|-----------|-------------|---------|------------|-------|
| Option 1 | 25,100 | ~20% | 450 MB | 50 MB | 500 MB |
| Option 2 | 25,000 | 0% | 420 MB | 80 MB | 500 MB |
| Option 3 | 25,000 | ~40% | 600 MB | 100 MB | 700 MB |
| Option 4 | 30,000 | ~50% | 700 MB | 100 MB | 800 MB |
| Option 5 | 24,100 | ~5% | 380 MB | 20 MB | 400 MB |

**Winner:** Option 5 (smallest, minimal duplication)

### 11.4 Scalability Projections

**Extrapolation to 10K Threads (Power User, 2+ Years)**

| Metric | Option 1 | Option 2 | Option 3 | Option 4 | Option 5 |
|--------|----------|----------|----------|----------|----------|
| Query Time | ~100ms | ~500ms | ~500s âŒ | ~10ms* | ~50ms |
| DB Size | ~8 GB | ~7 GB | ~12 GB | ~15 GB | ~6 GB |
| RAM Usage | ~200 MB | ~500 MB | ~5 GB âŒ | ~100 MB | ~150 MB |

*Option 4 fast but data may be stale

**Recommendation:** Only **Option 5** scales gracefully to 10K+ threads

### 11.5 Benchmark Implementation

**Create Benchmark Script:** `tools/benchmark_cross_thread_memory.py`

```python
import time
import sqlite3
import numpy as np
from typing import List, Dict
import matplotlib.pyplot as plt

class CrossThreadBenchmark:
    """Benchmark different cross-thread memory options."""
    
    def __init__(self):
        self.results = {}
    
    def setup_test_data(self, n_threads, n_memories_per_thread):
        """Create test databases for benchmarking."""
        # Create thread DBs
        for i in range(n_threads):
            thread_id = f"thread_{i:04d}"
            self.create_thread_db(thread_id, n_memories_per_thread)
        
        # Create global/profile DB (for applicable options)
        self.create_global_db(n_memories=100)
    
    def benchmark_option_1(self, query):
        """Benchmark Option 1: Global + Thread."""
        start = time.time()
        
        # Query global DB
        global_results = self.query_global_db(query)
        
        # Query thread DB
        thread_results = self.query_thread_db("thread_0001", query)
        
        # Merge results
        merged = self.merge_results(global_results, thread_results)
        
        elapsed = (time.time() - start) * 1000  # Convert to ms
        return elapsed
    
    def benchmark_option_5(self, query):
        """Benchmark Option 5: Profile + Thread."""
        start = time.time()
        
        # Query profile DB (small, ~100 facts)
        profile_results = self.query_profile_db(query)
        
        # Query thread DB
        thread_results = self.query_thread_db("thread_0001", query)
        
        # Merge with priority: thread override > profile > thread context
        merged = self.merge_hybrid_results(profile_results, thread_results)
        
        elapsed = (time.time() - start) * 1000
        return elapsed
    
    def run_benchmarks(self):
        """Run full benchmark suite."""
        thread_counts = [1, 10, 100, 500]
        
        for n_threads in thread_counts:
            print(f"\n=== Benchmarking with {n_threads} threads ===")
            self.setup_test_data(n_threads, n_memories_per_thread=50)
            
            # Test each option
            options = {
                "Option 1": self.benchmark_option_1,
                "Option 2": self.benchmark_option_2,
                "Option 3": self.benchmark_option_3,
                "Option 4": self.benchmark_option_4,
                "Option 5": self.benchmark_option_5,
            }
            
            for name, benchmark_fn in options.items():
                times = []
                for _ in range(10):  # Run 10 times for average
                    elapsed = benchmark_fn("What's my name?")
                    times.append(elapsed)
                
                avg_time = np.mean(times)
                std_time = np.std(times)
                
                print(f"{name}: {avg_time:.2f}ms Â± {std_time:.2f}ms")
                
                self.results[(name, n_threads)] = avg_time
        
        self.plot_results()
    
    def plot_results(self):
        """Plot benchmark results."""
        # Create visualization
        # ... (matplotlib code)
```

**Usage:**
```bash
cd /home/runner/work/AI_round2/AI_round2
python tools/benchmark_cross_thread_memory.py
```

**Expected Output:**
```
=== Benchmarking with 100 threads ===
Option 1: 15.23ms Â± 2.1ms
Option 2: 18.45ms Â± 3.2ms
Option 3: 5124.67ms Â± 234.5ms  âŒ TOO SLOW
Option 4: 5.12ms Â± 0.8ms
Option 5: 10.34ms Â± 1.5ms  âœ… BEST BALANCE

Recommendation: Option 5 (fast + fresh + scalable)
```


---

## 12. Migration Plan

### 12.1 Migration Overview (Option 5: Hybrid Profile + Context)

**Goal:** Migrate from current per-thread isolation to hybrid profile + context model

**Phases:**
1. **Analysis & Preparation** (2 days)
2. **Schema Implementation** (2 days)
3. **Data Migration** (2 days)
4. **Testing & Validation** (2 days)
5. **Deployment & Monitoring** (2 days)

**Total Timeline:** 10 days (2 weeks with buffer)

### 12.2 Phase 1: Analysis & Preparation (Days 1-2)

**Tasks:**

1. **Inventory Existing Threads**
   ```bash
   # Find all thread databases
   find personal_agent/ -name "crt_memory_*.db" -type f
   
   # Count threads per user (if multi-user)
   # Analyze memory counts per thread
   ```

2. **Identify Profile-Worthy Facts**
   ```python
   # Script: tools/analyze_profile_facts.py
   def analyze_threads():
       """Analyze all threads to identify profile-worthy facts."""
       threads = find_all_thread_dbs()
       
       profile_candidates = {}
       
       for thread_db in threads:
           memories = load_memories(thread_db)
           
           for memory in memories:
               slot = extract_slot(memory.text)
               
               if is_profile_worthy(slot, memory.trust):
                   if slot not in profile_candidates:
                       profile_candidates[slot] = []
                   
                   profile_candidates[slot].append({
                       'value': memory.text,
                       'trust': memory.trust,
                       'thread_id': memory.thread_id,
                       'timestamp': memory.timestamp
                   })
       
       # Analyze duplicates and conflicts
       for slot, candidates in profile_candidates.items():
           print(f"\nSlot: {slot}")
           print(f"  Occurrences: {len(candidates)}")
           
           values = [c['value'] for c in candidates]
           unique_values = set(values)
           
           if len(unique_values) > 1:
               print(f"  âš ï¸ CONFLICT: {unique_values}")
           else:
               print(f"  âœ… Consistent: {unique_values}")
   ```

3. **Backup All Data**
   ```bash
   # Create backup before migration
   mkdir -p backups/pre_migration_$(date +%Y%m%d)
   cp -r personal_agent/*.db backups/pre_migration_$(date +%Y%m%d)/
   ```

4. **Create Migration Scripts**
   - `migrate_to_profile.py` - Extract profile facts
   - `validate_migration.py` - Verify data integrity
   - `rollback_migration.py` - Rollback if needed

### 12.3 Phase 2: Schema Implementation (Days 3-4)

**1. Create Profile Database Schema**

```python
# File: personal_agent/user_profile.py (enhancement)

class UserProfile:
    def _init_db(self, user_id):
        """Initialize profile database."""
        db_path = f"personal_agent/user_profile_{user_id}.db"
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Profile facts table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS profile_facts (
                fact_id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                slot TEXT NOT NULL,
                value_text TEXT NOT NULL,
                trust REAL NOT NULL,
                confidence REAL NOT NULL,
                last_verified REAL NOT NULL,
                source_thread_id TEXT,
                vector_json TEXT,
                metadata_json TEXT,
                created_at REAL NOT NULL,
                updated_at REAL NOT NULL
            )
        """)
        
        # Indexes
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_profile_user_slot
            ON profile_facts(user_id, slot)
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_profile_trust
            ON profile_facts(trust DESC)
        """)
        
        # Profile contradiction ledger
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS profile_contradictions (
                ledger_id TEXT PRIMARY KEY,
                timestamp REAL NOT NULL,
                old_fact_id TEXT NOT NULL,
                new_memory_id TEXT NOT NULL,
                source_thread_id TEXT NOT NULL,
                drift_mean REAL NOT NULL,
                status TEXT NOT NULL,
                resolution_method TEXT,
                resolution_timestamp REAL,
                FOREIGN KEY (old_fact_id) REFERENCES profile_facts(fact_id)
            )
        """)
        
        conn.commit()
        conn.close()
```

**2. Update Thread Database Schema**

```python
# Migration script: tools/update_thread_schema.py

def update_thread_schema(thread_db_path):
    """Add profile-related columns to thread DB."""
    conn = sqlite3.connect(thread_db_path)
    cursor = conn.cursor()
    
    # Check if columns exist
    cursor.execute("PRAGMA table_info(memories)")
    columns = [row[1] for row in cursor.fetchall()]
    
    if "is_profile_override" not in columns:
        cursor.execute("""
            ALTER TABLE memories
            ADD COLUMN is_profile_override INTEGER DEFAULT 0
        """)
    
    if "profile_fact_id" not in columns:
        cursor.execute("""
            ALTER TABLE memories
            ADD COLUMN profile_fact_id TEXT
        """)
    
    conn.commit()
    conn.close()
```

### 12.4 Phase 3: Data Migration (Days 5-6)

**Migration Script:** `tools/migrate_to_profile.py`

```python
import sqlite3
import json
from typing import Dict, List
from personal_agent.user_profile import UserProfile
from personal_agent.crt_memory import CRTMemorySystem

PROFILE_SLOTS = {
    "name", "employer", "location", "age", "education",
    "preferences", "interests", "constraints", "expertise"
}

def migrate_threads_to_profile(user_id="default_user"):
    """Migrate thread memories to profile."""
    
    # 1. Initialize profile
    profile = UserProfile(user_id)
    
    # 2. Find all thread databases
    thread_dbs = find_thread_databases()
    
    # 3. Extract profile-worthy facts
    profile_candidates = {}
    
    for thread_db_path in thread_dbs:
        thread_id = extract_thread_id(thread_db_path)
        print(f"Processing thread: {thread_id}")
        
        conn = sqlite3.connect(thread_db_path)
        cursor = conn.cursor()
        
        # Query high-trust memories
        cursor.execute("""
            SELECT memory_id, text, trust, confidence, timestamp, vector_json
            FROM memories
            WHERE trust > 0.85 AND deprecated = 0
        """)
        
        for row in cursor.fetchall():
            memory_id, text, trust, confidence, timestamp, vector_json = row
            
            # Extract slot
            slot = extract_slot_from_text(text)
            
            # Check if profile-worthy
            if slot in PROFILE_SLOTS:
                if slot not in profile_candidates:
                    profile_candidates[slot] = []
                
                profile_candidates[slot].append({
                    'memory_id': memory_id,
                    'value': text,
                    'trust': trust,
                    'confidence': confidence,
                    'timestamp': timestamp,
                    'thread_id': thread_id,
                    'vector_json': vector_json
                })
        
        conn.close()
    
    # 4. Deduplicate and resolve conflicts
    for slot, candidates in profile_candidates.items():
        print(f"\nMigrating slot: {slot}")
        print(f"  Candidates: {len(candidates)}")
        
        # Group by value (semantic similarity)
        value_groups = group_by_semantic_similarity(candidates)
        
        if len(value_groups) == 1:
            # No conflict, pick highest trust
            best = max(candidates, key=lambda x: x['trust'])
            profile.add_fact(
                slot=slot,
                value_text=best['value'],
                trust=best['trust'],
                confidence=best['confidence'],
                source_thread_id=best['thread_id'],
                vector_json=best['vector_json']
            )
            print(f"  âœ… Migrated: {best['value']}")
        
        else:
            # Conflict detected
            print(f"  âš ï¸ CONFLICT: {len(value_groups)} different values")
            
            for i, group in enumerate(value_groups):
                best_in_group = max(group, key=lambda x: x['trust'])
                print(f"    {i+1}. {best_in_group['value']} (trust={best_in_group['trust']:.2f})")
            
            # For migration, pick highest trust across all groups
            best_overall = max(candidates, key=lambda x: x['trust'])
            profile.add_fact(
                slot=slot,
                value_text=best_overall['value'],
                trust=best_overall['trust'],
                confidence=best_overall['confidence'],
                source_thread_id=best_overall['thread_id'],
                vector_json=best_overall['vector_json']
            )
            print(f"  âš ï¸ Using highest trust: {best_overall['value']}")
            
            # Log contradiction for manual review
            log_migration_conflict(slot, value_groups)
    
    print(f"\nâœ… Migration complete. Profile has {len(profile_candidates)} facts.")

def group_by_semantic_similarity(candidates, threshold=0.9):
    """Group candidates by semantic similarity."""
    import numpy as np
    
    groups = []
    
    for candidate in candidates:
        # Check if belongs to existing group
        assigned = False
        
        for group in groups:
            # Compare with first item in group
            similarity = cosine_similarity(
                np.array(json.loads(candidate['vector_json'])),
                np.array(json.loads(group[0]['vector_json']))
            )
            
            if similarity > threshold:
                group.append(candidate)
                assigned = True
                break
        
        if not assigned:
            # Create new group
            groups.append([candidate])
    
    return groups
```

**Run Migration:**
```bash
cd /home/runner/work/AI_round2/AI_round2
python tools/migrate_to_profile.py --user-id default_user --dry-run

# Review conflicts, then run for real
python tools/migrate_to_profile.py --user-id default_user
```

### 12.5 Phase 4: Testing & Validation (Days 7-8)

**Validation Script:** `tools/validate_migration.py`

```python
def validate_migration(user_id):
    """Validate migration was successful."""
    
    print("=== Migration Validation ===\n")
    
    # 1. Check profile was created
    profile_db = f"personal_agent/user_profile_{user_id}.db"
    assert os.path.exists(profile_db), "Profile DB not created"
    print("âœ… Profile database exists")
    
    # 2. Count profile facts
    conn = sqlite3.connect(profile_db)
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM profile_facts")
    fact_count = cursor.fetchone()[0]
    print(f"âœ… Profile has {fact_count} facts")
    
    # 3. Check no data loss
    # Compare total memories before/after
    original_count = count_memories_in_threads()
    print(f"   Original thread memories: {original_count}")
    
    # 4. Test retrieval
    from personal_agent.crt_rag import CRTEnhancedRAG
    
    rag = CRTEnhancedRAG()
    
    test_queries = [
        "What's my name?",
        "Where do I work?",
        "What's my location?"
    ]
    
    for query in test_queries:
        results = rag.retrieve_with_profile(query, thread_id="new_thread", user_id=user_id)
        print(f"   Query: {query}")
        print(f"   Results: {len(results)} memories found")
        
        if results:
            print(f"   Top result: {results[0].text}")
    
    print("\nâœ… Validation complete")
```

**Integration Tests:**
```python
# tests/test_cross_thread_memory.py

def test_profile_retrieval():
    """Test cross-thread retrieval with profile."""
    user_id = "test_user"
    
    # Setup: Create profile with facts
    profile = UserProfile(user_id)
    profile.add_fact("name", "Nick", trust=0.9, ...)
    profile.add_fact("employer", "Google", trust=0.9, ...)
    
    # Test: New thread should see profile facts
    rag = CRTEnhancedRAG()
    results = rag.retrieve_memories("What's my name?", thread_id="new_thread", user_id=user_id)
    
    assert len(results) > 0, "Should find name in profile"
    assert "Nick" in results[0].text, "Should retrieve correct name"

def test_thread_override():
    """Test thread-specific override of profile."""
    user_id = "test_user"
    
    # Setup: Profile has name=Nick
    profile = UserProfile(user_id)
    profile.add_fact("name", "Nick", trust=0.9, ...)
    
    # Test: Thread overrides with Nicholas
    rag = CRTEnhancedRAG()
    rag.store_memory(
        "Call me Nicholas here",
        thread_id="thread_42",
        user_id=user_id,
        is_profile_override=True
    )
    
    # Query in thread 42
    results = rag.retrieve_memories("What's my name?", thread_id="thread_42", user_id=user_id)
    assert "Nicholas" in results[0].text, "Should use thread override"
    
    # Query in different thread
    results = rag.retrieve_memories("What's my name?", thread_id="thread_99", user_id=user_id)
    assert "Nick" in results[0].text, "Should use profile in other threads"
```

### 12.6 Phase 5: Deployment & Monitoring (Days 9-10)

**Deployment Steps:**

1. **Gradual Rollout**
   ```python
   # Feature flag in runtime_config.py
   ENABLE_CROSS_THREAD_MEMORY = os.getenv("ENABLE_CROSS_THREAD", "false") == "true"
   
   def retrieve_memories(query, thread_id, user_id):
       if ENABLE_CROSS_THREAD_MEMORY:
           return retrieve_with_profile(query, thread_id, user_id)
       else:
           return retrieve_thread_only(query, thread_id)
   ```

2. **Monitor Performance**
   ```python
   # Add metrics
   import time
   
   def retrieve_with_profile(query, thread_id, user_id):
       start = time.time()
       results = ... # Retrieval logic
       elapsed = time.time() - start
       
       # Log metrics
       logger.info(f"[PERF] Profile retrieval: {elapsed*1000:.2f}ms")
       
       if elapsed > 0.1:  # 100ms threshold
           logger.warning(f"[PERF] Slow retrieval: {elapsed*1000:.2f}ms")
       
       return results
   ```

3. **User Communication**
   - Update docs: "CRT now remembers facts across conversations!"
   - Add UI indicator: "Using profile from 5 previous conversations"
   - Privacy notice: "You can manage your profile in Settings"

### 12.7 Rollback Strategy

**If Migration Fails:**

```bash
# Stop services
systemctl stop crt_api

# Restore from backup
rm -rf personal_agent/*.db
cp -r backups/pre_migration_YYYYMMDD/* personal_agent/

# Disable feature flag
export ENABLE_CROSS_THREAD=false

# Restart services
systemctl start crt_api
```

**Rollback Script:** `tools/rollback_migration.py`

```python
def rollback_migration(backup_dir):
    """Rollback to pre-migration state."""
    import shutil
    
    print("âš ï¸ Rolling back migration...")
    
    # Delete profile DBs
    for profile_db in find_profile_databases():
        os.remove(profile_db)
        print(f"   Deleted: {profile_db}")
    
    # Restore thread DBs from backup
    for backup_file in os.listdir(backup_dir):
        if backup_file.endswith(".db"):
            shutil.copy(
                f"{backup_dir}/{backup_file}",
                f"personal_agent/{backup_file}"
            )
            print(f"   Restored: {backup_file}")
    
    print("âœ… Rollback complete")
```


---

## 13. Recommended Approach

### 13.1 Final Recommendation: Option 5 (Hybrid Profile + Thread Context)

**Decision:** Implement **Option 5: Hybrid Profile + Thread Context**

**Rationale:**

| Factor | Why Option 5 Wins |
|--------|-------------------|
| **UX Quality** | Users naturally understand "profile" (name, job) vs "context" (this conversation) |
| **Performance** | Profile is small (~100 facts), queries are fast (~10ms), scales to 10K+ threads |
| **Privacy** | Profile separate from threads, sensitive data stays thread-isolated |
| **Implementation** | Moderate effort (2 weeks), but clean architecture pays off long-term |
| **Scalability** | Profile grows slowly (only stable facts), threads stay small |
| **Industry Alignment** | Matches proven patterns (agent-zero, LangChain, ChatGPT memory) |
| **User Control** | Easy to build "Your Profile" UI, users can review/edit |
| **Future-Proof** | Supports multi-device sync (profile syncs, threads local) |

### 13.2 Implementation Roadmap

**Timeline: 2 Weeks (10 Business Days)**

#### Week 1: Foundation & Migration

**Day 1-2: Analysis & Design**
- [ ] Run analysis script on existing threads (`tools/analyze_profile_facts.py`)
- [ ] Identify conflicts (same slot, different values across threads)
- [ ] Create detailed migration plan per user (if multi-user)
- [ ] Design profile UI mockups (optional but recommended)
- [ ] Set up feature flag system

**Day 3-4: Schema & Core Logic**
- [ ] Implement `UserProfile` class (`personal_agent/user_profile.py`)
- [ ] Create profile database schema
- [ ] Update `CRTMemorySystem` to support profile override flags
- [ ] Modify `CRTEnhancedRAG` retrieval logic (profile + thread merging)
- [ ] Implement profile-worthy classification logic

**Day 5-6: Data Migration**
- [ ] Write migration script (`tools/migrate_to_profile.py`)
- [ ] Backup all existing databases
- [ ] Run migration in dry-run mode, review conflicts
- [ ] Resolve conflicts (manual review or highest-trust heuristic)
- [ ] Execute migration for real
- [ ] Validate data integrity

#### Week 2: Testing & Deployment

**Day 7-8: Testing**
- [ ] Unit tests for `UserProfile` class
- [ ] Unit tests for profile + thread merging logic
- [ ] Integration tests for cross-thread retrieval
- [ ] Integration tests for thread override
- [ ] Performance benchmarks (verify <50ms query time)
- [ ] Privacy tests (sensitive data not in profile)

**Day 9: Deployment**
- [ ] Deploy with feature flag disabled
- [ ] Enable for 10% of users (canary testing)
- [ ] Monitor performance metrics
- [ ] Monitor error logs
- [ ] Collect user feedback

**Day 10: Rollout & Documentation**
- [ ] Enable for 100% of users (if canary successful)
- [ ] Update user documentation
- [ ] Update developer documentation
- [ ] Create "Your Profile" UI (if not done in Week 1)
- [ ] Announce feature to users

### 13.3 Success Metrics

**Quantitative:**
- [ ] Query latency < 50ms (p95)
- [ ] Profile extraction accuracy > 95% (manual review of sample)
- [ ] Zero data loss during migration
- [ ] User retention maintained or improved
- [ ] Support tickets about "forgetting" reduced by >80%

**Qualitative:**
- [ ] Users report natural conversation flow across threads
- [ ] Users understand and trust the profile concept
- [ ] Developers find code maintainable and extensible

### 13.4 Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Data loss during migration** | Low | Critical | Full backup before migration, dry-run mode, validation script |
| **Performance degradation** | Low | High | Benchmark before deployment, feature flag for instant rollback |
| **User confusion** | Medium | Medium | Clear UI, documentation, gradual rollout with feedback |
| **Privacy violations** | Low | Critical | Strict sensitive-slot filtering, user control, audit logging |
| **Profile bloat** | Medium | Medium | Strict profile-worthy criteria, periodic cleanup, user review UI |
| **Migration conflicts** | High | Medium | Conflict detection, manual review for important facts, user confirmation |

### 13.5 Post-Implementation Enhancements

**Phase 2 (Future):**

1. **ML-Based Profile Classification**
   - Train model to classify facts as profile/context
   - Features: slot type, trust, confirmation count, user edits
   - Reduces manual heuristic maintenance

2. **Profile Sync Across Devices**
   - Profile DB syncs to cloud (threads stay local)
   - Enables multi-device UX (phone, desktop, web)

3. **Profile Timeline View**
   - UI showing how profile evolved over time
   - "Employer: Microsoft (2022) â†’ Google (2024)"

4. **Conflict Resolution UI**
   - User-friendly interface for resolving contradictions
   - "We found two values for 'employer': Microsoft (2 weeks ago, 3 threads) vs Google (yesterday, 1 thread). Which is correct?"

5. **Profile Sharing** (Advanced)
   - Share profile with team (e.g., "Here's what the AI knows about me")
   - Privacy controls per fact

### 13.6 Alternative: Staged Rollout

If 2-week timeline is too aggressive, consider **3-phase rollout**:

**Phase 1: Read-Only Profile (1 week)**
- Create profile DB, extract facts
- Query profile for retrieval
- Don't update profile yet (read-only)
- Validate UX improvement

**Phase 2: Profile Updates (1 week)**
- Implement profile update logic
- Handle contradictions
- Test extensively

**Phase 3: Thread Overrides (1 week)**
- Implement thread override functionality
- Build profile management UI
- Full feature complete

**Total: 3 weeks (safer, but slower)**

### 13.7 Conclusion

**Option 5 (Hybrid Profile + Thread Context)** is the clear winner because it:

âœ… **Solves the user pain point** - Remembers facts across threads naturally  
âœ… **Maintains CRT principles** - Trust, contradictions, provenance all preserved  
âœ… **Performs well** - Fast queries even at scale (10K+ threads)  
âœ… **Protects privacy** - Sensitive data stays thread-isolated  
âœ… **Aligns with industry** - Proven pattern used by agent-zero, LangChain, ChatGPT  
âœ… **Enables future features** - Profile sync, timeline view, sharing  

**Next Steps:**
1. Review and approve this design document
2. Assign engineering resources (1-2 developers)
3. Start Week 1 tasks (analysis & schema design)
4. Implement according to roadmap
5. Ship in 2 weeks! ðŸš€

---

**Document Prepared By:** CRT System Architecture Team  
**Date:** January 23, 2026  
**Status:** Ready for Implementation  
**Estimated Effort:** 2 weeks (1-2 developers)  

**Approval Required From:**
- [ ] Engineering Lead
- [ ] Product Manager
- [ ] Privacy/Security Officer

---

**Appendix A: References**

- agent-zero memory system: https://github.com/agent0ai/agent-zero/tree/main/python/helpers/memory.py
- LangChain memory patterns: https://python.langchain.com/docs/modules/memory/
- CRT Whitepaper: `CRT_WHITEPAPER.md`
- Current Memory System: `personal_agent/crt_memory.py`
- Current RAG System: `personal_agent/crt_rag.py`

**Appendix B: Glossary**

- **Profile** - Stable, cross-thread facts about the user (name, job, preferences)
- **Thread** - A single conversation session
- **Context** - Ephemeral, thread-specific memories
- **Slot** - Fact category (e.g., "name", "employer", "age")
- **Trust** - Validated reliability score (evolves over time)
- **Confidence** - Initial certainty score (fixed at creation)
- **SSE Mode** - Semantic compression level (L/C/H)

