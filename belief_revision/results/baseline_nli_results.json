{
  "method": "NLI-Based (Pre-trained NLI)",
  "description": "Natural Language Inference for contradiction detection",
  "model_type": "Pre-trained NLI",
  "category_evaluation": {
    "test_set": "Phase 2 test set (90 examples)",
    "accuracy": 0.5333333333333333,
    "macro_precision": 0.5859375,
    "macro_recall": 0.5434782608695652,
    "macro_f1": 0.4519810508182601,
    "per_category_metrics": {
      "REFINEMENT": {
        "precision": 0.34375,
        "recall": 1.0,
        "f1": 0.5116279069767442,
        "support": 22
      },
      "REVISION": {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "support": 23
      },
      "TEMPORAL": {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "support": 22
      },
      "CONFLICT": {
        "precision": 1.0,
        "recall": 0.17391304347826086,
        "f1": 0.2962962962962963,
        "support": 23
      }
    }
  },
  "policy_evaluation": {
    "test_set": "Phase 3 test set (90 examples)",
    "accuracy": 0.6666666666666666,
    "macro_precision": 0.6931818181818182,
    "macro_recall": 0.6594686907020874,
    "macro_f1": 0.6648706896551725,
    "per_policy_metrics": {
      "OVERRIDE": {
        "precision": 0.9583333333333334,
        "recall": 0.6764705882352942,
        "f1": 0.7931034482758621,
        "support": 34
      },
      "PRESERVE": {
        "precision": 0.696969696969697,
        "recall": 0.7419354838709677,
        "f1": 0.71875,
        "support": 31
      },
      "ASK_USER": {
        "precision": 0.42424242424242425,
        "recall": 0.56,
        "f1": 0.4827586206896552,
        "support": 25
      }
    }
  }
}